{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"jaime Sendra Berenguer","title":"Home"},{"location":"about/","text":"Jiame Sendra Berenguer","title":"About"},{"location":"license/","text":"","title":"License"},{"location":"01_Blog/01_Pipeline_NN/doc/Pipeline_para_el_entrenamiento_de_Redes_Neuronales/","text":"Pipeline para el entrenamiento de Redes Neuronales El objetivo de este post es exponer un proceso especifico cuando se requiera aplicar una red neuronal para abordar un nuevo problema. Se basa en construir la red de simple a complejo, y en cada paso del camino hacer hip\u00f3tesis concretas de lo que se espera que ocurra y posteriormente validarlas con un conjunto de experimentaci\u00f3n que nos permita la detecci\u00f3n pronta de posibles problemas en la arquitectura. Con todo ello, lo que se intenta evitar es introducir una complejidad excesiva a nuestro problema que seguramente introducir\u00e1 errores o configuraciones err\u00f3neas muy dif\u00edciles o casi imposibles de detectar, ya que su red mal configurada, la mayor\u00eda de las veces entrenar\u00e1 sin arrojar excepciones, aunque en silencio funcionar\u00e1 un poco peor. An\u00e1lisis y limpieza de los Datos El primer paso antes de empezar a crear o desarrollar la arquitectura de la red neuronal es comenzar inspeccionando a fondo sus datos. Este paso es muy cr\u00edtico y por ello se debe dedicar una gran parte del tiempo total al escaneando de miles de ejemplos, entendiendo su distribuci\u00f3n y buscando patrones. Algunas consideraciones a tener en cuenta en el an\u00e1lisis exploratorio y limpieza de datos ser\u00edan: Datos duplicados, en el caso de datos estructurados pueden ser lineas del dataframe repetidas o en el caso de im\u00e1genes podr\u00edan ser copias duplicadas con o sin el mismo nombre. Etiquetas corruptas, datos faltantes o datos inconsistentes. Valores at\u00edpicos en cualquiera de las variables independientes. B\u00fasqueda de los desequilibrios de datos y posibles sesgos en las variables independientes. Estudio que toman la variaci\u00f3n de las variables dependientes. Reducci\u00f3n en la resoluci\u00f3n de las im\u00e1genes siempre que la calidad del detalle sea la apropiada. Posible ruido en las etiquetas o incluso en alguna variable dependiente. Transformaciones de los datos para adaptar la varianza de los datos a una distribuci\u00f3n normal. Categorizaci\u00f3n de las variables categ\u00f3ricas. Descarga del dataset de ejemplo: data_directory = \"dataset/\" folder_data = \"PetImages/\" directory = os.path.join(data_directory, folder_data) if not os.path.isdir(data_directory): os.mkdir(data_directory) !curl -o dataset/kagglecatsanddogs.zip https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip !unzip -q dataset/kagglecatsanddogs.zip -d dataset/ # Forzar desbalanceo del dataset items_cats = [item for item in os.listdir(os.path.join(directory, \"Cat\")) if os.path.isfile(os.path.join(directory, \"Cat\", item))] _ = [os.remove(os.path.join(directory, \"Cat\", item)) for item in rn.choices(items_cats, k=int(len(items_cats)*0.5)) if os.path.isfile(os.path.join(directory, \"Cat\", item))] !ls dataset/PetImages/ >>> Cat Dog Filtrado de imagenes corruptas num_skipped = 0 for folder_name in (\"Cat\", \"Dog\"): folder_path = os.path.join(directory, folder_name) for fname in os.listdir(folder_path): fpath = os.path.join(folder_path, fname) try: fobj = open(fpath, \"rb\") is_jfif = tf.compat.as_bytes(\"JFIF\") in fobj.peek(10) finally: fobj.close() if not is_jfif: num_skipped += 1 # Delete corrupted image os.remove(fpath) print(\"Deleted %d images\" % num_skipped) >>> Deleted 0 images Resumen de los Datos del dataset items_cats = [item for item in os.listdir(os.path.join(directory, \"Cat\")) if os.path.isfile(os.path.join(directory, \"Cat\", item))] items_dogs = [item for item in os.listdir(os.path.join(directory, \"Dog\")) if os.path.isfile(os.path.join(directory, \"Dog\", item))] print(f'Numero de imagenes correspondientes a gatos: {len(items_cats)}') print(f'Numero de imagenes correspondientes a perros: {len(items_dogs)}') print(f'Relaci\u00f3n de desbalanceo gatos/perros: {len(items_cats)/len(items_dogs)}') >>> Numero de imagenes correspondientes a gatos: 7163 >>> Numero de imagenes correspondientes a perros: 11670 >>> Relaci\u00f3n de desbalanceo gatos/perros: 0.613796058269066 Generaci\u00f3n del Dataset image_size = (204, 204) batch_size = 32 num_classes = 2 train_ds = tf.keras.preprocessing.image_dataset_from_directory( directory, validation_split=0.2, subset=\"training\", seed=seed, image_size=image_size, batch_size=batch_size, ) val_ds = tf.keras.preprocessing.image_dataset_from_directory( directory, validation_split=0.2, subset=\"validation\", seed=seed, image_size=image_size, batch_size=batch_size, ) train_ds = train_ds.prefetch(buffer_size=batch_size) val_ds = val_ds.prefetch(buffer_size=batch_size) >>> Found 18831 files belonging to 2 classes. >>> Using 15065 files for training. >>> Found 18831 files belonging to 2 classes. >>> Using 3766 files for validation. Visualizaci\u00f3n de los datos plt.figure(figsize=(10, 6)) for images, labels in train_ds.take(1): for i in range(8): ax = plt.subplot(2, 4, i + 1) plt.imshow(images[i].numpy().astype(\"uint8\")) plt.title(\"Cat\" if int(labels[i]) == 0 else \"Dog\") plt.axis(\"off\") Configuraci\u00f3n de la arquitectura end-to-end. Una vez entendidos los datos, el siguiente paso es configurar la funci\u00f3n de entrenamiento y evaluaci\u00f3n, que nos permita ejecutarla y ganar confianza en su inferencia a trav\u00e9s de una serie de experimentos. en esta etapa, es muy recomendable elegir un modelo simple, el cual no ha sido modificado de ninguna manera, por ejemplo, un clasificador lineal o un red convolucional simple. Con ello, el objetivo ser\u00e1 entrenarlo, visualizar las p\u00e9rdidas y las m\u00e9tricas para cada epoch, predecir resultados en base a la inferencia del modelo y realizar una serie de experimentos de ablaci\u00f3n con hip\u00f3tesis expl\u00edcitas en cada experimento realizado. Generaci\u00f3n red convolucional simple def make_model(input_shape, num_classes): inputs = keras.Input(shape=input_shape) # Entry block x = layers.experimental.preprocessing.Rescaling(1.0 / 255)(inputs) x = layers.Conv2D(32, 3, strides=3, padding=\"same\")(x) x = layers.Activation(\"relu\")(x) x = layers.MaxPool2D(pool_size=2)(x) x = layers.Conv2D(32, 3, strides=3, padding=\"same\")(x) x = layers.Activation(\"relu\")(x) x = layers.GlobalAveragePooling2D()(x) if num_classes == 2: activation = \"sigmoid\" units = 1 else: activation = \"softmax\" units = num_classes initializer_weights = tf.keras.initializers.GlorotUniform() initializer_bias = tf.constant_initializer(0.6) outputs = layers.Dense(units, bias_initializer = initializer_bias, kernel_initializer = initializer_weights, activation = activation)(x) return keras.Model(inputs, outputs) model = make_model(input_shape=image_size + (3,), num_classes=num_classes) model.summary() >>> Model: \"functional_1\" >>> _________________________________________________________________ >>> Layer (type) Output Shape Param # >>> ================================================================= >>> input_1 (InputLayer) [(None, 224, 224, 3)] 0 >>> _________________________________________________________________ >>> rescaling (Rescaling) (None, 224, 224, 3) 0 >>> _________________________________________________________________ >>> conv2d (Conv2D) (None, 75, 75, 32) 896 >>> _________________________________________________________________ >>> activation (Activation) (None, 75, 75, 32) 0 >>> _________________________________________________________________ >>> max_pooling2d (MaxPooling2D) (None, 37, 37, 32) 0 >>> _________________________________________________________________ >>> conv2d_1 (Conv2D) (None, 13, 13, 32) 9248 >>> _________________________________________________________________ >>> activation_1 (Activation) (None, 13, 13, 32) 0 >>> _________________________________________________________________ >>> global_average_pooling2d (Gl (None, 32) 0 >>> _________________________________________________________________ >>> dense (Dense) (None, 1) 33 >>> ================================================================= >>> Total params: 10,177 >>> Trainable params: 10,177 >>> Non-trainable params: 0 >>> _________________________________________________________________ Funci\u00f3n de entrenamiento EPOCHS = 5 #Par\u00e1metro general en el Pipeline de entrenamiento model.compile( optimizer=keras.optimizers.Adam(1e-3), loss=\"binary_crossentropy\", metrics=[\"accuracy\"], ) history = model.fit( train_ds, epochs=EPOCHS, validation_data=val_ds, validation_steps = len(val_ds) ) >>> Epoch 1/5 >>> 471/471 [==============================] - 49s 104ms/step - loss: 0.6647 - accuracy: 0.6117 - >>> val_loss: 0.6313 - val_accuracy: 0.6283 >>> Epoch 2/5 >>> 471/471 [==============================] - 48s 101ms/step - loss: 0.6322 - accuracy: 0.6346 - >>> val_loss: 0.6266 - val_accuracy: 0.6306 >>> ... >>> ... >>> Epoch 98/100 >>> 472/472 [==============================] - 43s 92ms/step - loss: 0.4487 - accuracy: 0.7835 - >>> val_loss: 0.4857 - val_accuracy: 0.7596 >>> Epoch 99/100 >>> 472/472 [==============================] - 43s 91ms/step - loss: 0.4510 - accuracy: 0.7892 - >>> val_loss: 0.4920 - val_accuracy: 0.7537 >>> Epoch 100/100 >>> 472/472 [==============================] - 43s 91ms/step - loss: 0.4509 - accuracy: 0.7881 - >>> val_loss: 0.5077 - val_accuracy: 0.7503 Funci\u00f3n de evaluaci\u00f3n def plot_history(history): \"\"\" Generaci\u00f3n del gr\u00e1fico de Visualizaci\u00f3n de m\u00e9tricas y perdidas para cada epochs del entrenamiento-validaci\u00f3n. \"\"\" acc = history.history['accuracy'] val_acc = history.history['val_accuracy'] loss = history.history['loss'] val_loss = history.history['val_loss'] epochs = range(1, len(acc)+1, 1) fig, axs = plt.subplots(1, 2,figsize=(12, 5)) axs[0].plot(epochs, acc, 'r--', label='Training acc') axs[0].plot(epochs, val_acc, 'b', label='Validation acc') axs[0].set_title('Training and validation accuracy') axs[0].set_ylabel('acc') axs[0].set_xlabel('epochs') axs[0].legend() axs[1].plot(epochs, loss, 'r--' ) axs[1].plot(epochs, val_loss , 'b' ) axs[1].set_title ('Training and validation loss') axs[1].set_ylabel('loss') axs[1].set_xlabel('epochs') fig.tight_layout() plt.show() plot_history(history) Sugerencias a tener en cuenta Algunas sugerencias en este paso son: Semilla aleatoria fija: esto garantiza la repetibilidad de sus experimentos, eliminando el factor de variaci\u00f3n y permitiendo que pueda comparar los distintos experimentos. ```python Configurar las semillas para reproducibilidad os.environ['PYTHONHASHSEED'] = '0' seed = 99 np.random.seed(seed) rn.seed(seed) tf.random.set_seed(seed) ``` Simplificar: En esta etapa es muy importante simplificar el pipeline de entrenamiento, es decir, deshabilitar cualquier m\u00e9todo de regulaci\u00f3n a\u00f1adido como por ejemplo podr\u00eda ser el aumento de datos, que pueda inducir alg\u00fan tipo de error en la red. Visualizaci\u00f3n del tensor de entrada de la red: Muy importante preparar en su c\u00f3digo la visualizaci\u00f3n del tensor de entrada a la red. Con ello se asegura la consistencia de los datos de entrada y ayuda a la detecci\u00f3n temprana de fallos en el aumento de datos o en la codificaci\u00f3n de estos. python train_ds.as_numpy_iterator().next()[0].shape >>> (32, 224, 224, 3) Agregar datos significativos en la evaluaci\u00f3n: Evaluar la p\u00e9rdida de evaluaci\u00f3n en todo el conjunto de test. python history = model.fit( train_ds, epochs=EPOCHS, callbacks=callbacks, validation_data=val_ds, validation_steps = total_imag_val // batch_size # con generador: validation_steps = len(val_ds) ) Visualizaci\u00f3n de la din\u00e1mica de predicci\u00f3n: Se pretende visualizar las predicciones del modelo en un lote de prueba fijo durante la inferencia. Esta din\u00e1mica de c\u00f3mo var\u00edan las predicciones permiten intuir de buena manera el progreso de entrenamiento.Si se observa gran variabilidad y fluctuaciones demasiado agresivas, esto es s\u00edntoma de inestabilidades en el proceso de entrenamiento. Verificar la p\u00e9rdida en la inicializaci\u00f3n: Verificar que su p\u00e9rdida comience en un valor de inicializaci\u00f3n correcto. El objetivo de la inicializaci\u00f3n de peso es evitar que las salidas de activaci\u00f3n de la capa exploten o desaparezcan durante el proceso de forward pass de la red neuronal profunda. Si ocurre cualquiera de los dos, los gradientes de p\u00e9rdida ser\u00e1n demasiado grandes o demasiado peque\u00f1os para fluir hacia atr\u00e1s de manera beneficiosa, y la red tardar\u00e1 m\u00e1s en converger, si es que es capaz de hacerlo. Para conseguir una convengencia sustancialmente m\u00e1s r\u00e1pida y una mayor precisi\u00f3n en los resultados, la mejor forma es inicializar los pesos con un inicializador de pesos GlorotNormal o GlorotUniform . python initializer_weights = tf.keras.initializers.GlorotUniform() outputs = layers.Dense(units, kernel_initializer = initializer_weights, activation = activation)(x) Inicializaci\u00f3n de los pesos: Inicializaci\u00f3n de los pesos de las capas finales de manera correcta. Por ejemplo, si se tiene un conjunto de datos desequilibrado a relaci\u00f3n 1:5, se debe asignar el sesgo en los logits de modo que la red sea capaz de predecir la probabilidad de 0.25 en la inicializaci\u00f3n. Esta inicializaci\u00f3n ayudar\u00e1 a la red a converger de manera m\u00e1s r\u00e1pida y eliminar\u00e1 las primeras iteraciones del entrenamiento, donde la red esta aprendiendo el sesgo del conjunto de datos. python print(f'Relaci\u00f3n en el desbalanceo gatos/perros: {len(items_cats)/len(items_dogs)}') >>> Relaci\u00f3n de desbalanceo gatos/perros: 0.613796058269066 En este caso la relaci\u00f3n de desequilibrio entre las dos categorias es de un 0.6 aproximadamente, por ello: python initializer_weights = tf.keras.initializers.GlorotUniform() initializer_bias = tf.constant_initializer(0.6) outputs = layers.Dense(units, bias_initializer = initializer_bias, kernel_initializer = initializer_weights, activation = activation)(x) Razonamiento humano: Monitorizaci\u00f3n de las m\u00e9tricas que no sean p\u00e9rdidas y que aporten m\u00e1s valor al \"ojo humano\", como por ejemplo la precisi\u00f3n siempre que sea posible. Con ello se puede hacer una trazabilidad de los resultados para cada iteraci\u00f3n que sean interpretables desde el programador. python model.compile( optimizer=keras.optimizers.Adam(1e-3), loss=\"binary_crossentropy\", metrics=[\"accuracy\"], ) Independencia de los datos de entrada: Esto se basa en hacer la prueba de entrenar la red neuronal en base a todas las entradas a cero. En este caso la red deber\u00eda funcionar peor que con los datos reales del conjunto de entrenamiento. Si es as\u00ed, se est\u00e1 validando que la red es capaz de extraer informaci\u00f3n de las entradas. En vez de aplicar todas las entradas a zero, se puede establecer una capa de abandono en la entrada, con una tasa/frecuencia de abandono muy alta, con lo que conseguira que practicamente todos los elementos del tensor de entrada sean igual a zero. ```python def make_model_zeros(input_shape, num_classes): inputs = keras.Input(shape=input_shape) x = tf.keras.layers.Dropout(0.99)(inputs) #Aplica Dropout a la entrada. x = layers.Conv2D(32, 3, strides=3, padding=\"same\")(x) x = layers.Activation(\"relu\")(x) x = layers.MaxPool2D(pool_size=2)(x) x = layers.Conv2D(32, 3, strides=3, padding=\"same\")(x) x = layers.Activation(\"relu\")(x) x = layers.GlobalAveragePooling2D()(x) if num_classes == 2: activation = \"sigmoid\" units = 1 else: activation = \"softmax\" units = num_classes initializer_weights = tf.keras.initializers.GlorotUniform() initializer_bias = tf.constant_initializer(0.6) outputs = layers.Dense(units, bias_initializer = initializer_bias, kernel_initializer = initializer_weights, activation = activation)(x) return keras.Model(inputs, outputs) model_zeros = make_model_zeros(input_shape=image_size + (3,), num_classes=num_classes) model_zeros.compile( optimizer=keras.optimizers.Adam(1e-3), loss=\"binary_crossentropy\", metrics=[\"accuracy\"], ) history_zeros = model_zeros.fit( train_ds, epochs=EPOCHS, validation_data=val_ds, validation_steps = len(val_ds) ) ``` >>> Epoch 1/5 >>> 471/471 [==============================] - 49s 103ms/step - loss: 21.5472 - accuracy: 0.5310 - >>> val_loss: 0.6932 - val_accuracy: 0.6190 >>> Epoch 2/5 >>> 471/471 [==============================] - 47s 101ms/step - loss: 1.6109 - accuracy: 0.5280 - >>> val_loss: 0.6682 - val_accuracy: 0.6190 >>> Epoch 3/5 >>> 471/471 [==============================] - 48s 102ms/step - loss: 0.8016 - accuracy: 0.5523 - >>> val_loss: 0.6656 - val_accuracy: 0.6190 >>> ... >>> ... >>> Epoch 98/100 >>> 472/472 [==============================] - 43s 92ms/step - loss: 0.6625 - accuracy: 0.6141 - >>> val_loss: 0.6700 - val_accuracy: 0.6194 >>> Epoch 99/100 >>> 472/472 [==============================] - 44s 93ms/step - loss: 0.6636 - accuracy: 0.6146 - >>> val_loss: 0.6702 - val_accuracy: 0.6194 >>> Epoch 100/100 >>> 472/472 [==============================] - 43s 92ms/step - loss: 0.6644 - accuracy: 0.6131 - >>> val_loss: 0.6709 - val_accuracy: 0.6194 python plot_history(history_zeros) Como se puede observar, la red con una capa de abandono en la entrada no es capaz de converger y por ello no aprende. Con ello, ya que la red base si que convergue, se valida que la red es capaz de extraer informaci\u00f3n de las entradas y como consecuencia se puede decir que el modelo es dependiente de las entradas, es decir, es capaz de extraer informaci\u00f3n de las imagenes de entrada. Sobreajuste en un lote: Se basa en el sobreajuste de un lote de unos poqu\u00edsimos ejemplos, con el objetivo de alcanzar la p\u00e9rdida m\u00e1s baja posible. Para ello se puede aumentar las capacidades de la red, aumentando el n\u00famero de capas o filtros. El objetivo es asegurar que tanto la etiqueta como la predicci\u00f3n coinciden al alcanzar la p\u00e9rdida m\u00ednima, si no es as\u00ed, es s\u00edntoma de que hay alg\u00fan error en alguna parte. Toma de un \u00fanico lote para el entrenamiento ```python Se toma un lote a partir del generador, que servir\u00e1 como lote a sobreajustar en el entrenamiento: X_train, y_train = train_ds.as_numpy_iterator().next() X_train.shape, y_train.shape ``` >>> ((32, 224, 224, 3), (32,)) Modelo y funci\u00f3n de entrenamiento ```python def make_model_overfiting(input_shape, num_classes): inputs = keras.Input(shape=input_shape) x = layers.Conv2D(32, 3, strides=3, padding=\"same\")(inputs) x = layers.Activation(\"relu\")(x) x = layers.MaxPool2D(pool_size=2)(x) x = layers.Conv2D(32, 3, strides=3, padding=\"same\")(x) x = layers.Activation(\"relu\")(x) x = layers.GlobalAveragePooling2D()(x) if num_classes == 2: activation = \"sigmoid\" units = 1 else: activation = \"softmax\" units = num_classes initializer_weights = tf.keras.initializers.GlorotUniform() initializer_bias = tf.constant_initializer(0.6) outputs = layers.Dense(units, bias_initializer = initializer_bias, kernel_initializer = initializer_weights, activation = activation)(x) return keras.Model(inputs, outputs) model_overfiting = make_model_overfiting(input_shape=image_size + (3,), num_classes=num_classes) model_overfiting.compile(pip install matplotlib optimizer=keras.optimizers.Adam(1e-3), loss=\"binary_crossentropy\", metrics=[\"accuracy\"], ) history_overfiting = model_overfiting.fit( X_train, y_train, validation_data=val_ds.take(1), validation_steps = len(val_ds.take(1)), epochs=240) #Se eligue un n\u00famero alto de epochs para poder llegar al sobreajuste. ``` >>> Epoch 1/240 >>> 1/1 [==============================] - 1s 1s/step - loss: 13.0985 - accuracy: 0.5312 - >>> val_loss: 3.7622 - val_accuracy: 0.4062 >>> Epoch 2/240 >>> 1/1 [==============================] - 1s 712ms/step - loss: 2.9530 - accuracy: 0.5625 - >>> val_loss: 8.5338 - val_accuracy: 0.3750 >>> Epoch 3/240 >>> 1/1 [==============================] - 1s 690ms/step - loss: 6.6881 - accuracy: 0.4688 - >>> val_loss: 7.3043 - val_accuracy: 0.5625 >>> ... >>> ... >>> Epoch 239/240 >>> 1/1 [==============================] - 1s 692ms/step - loss: 0.0461 - accuracy: 1.0000 - >>> val_loss: 5.1547 - val_accuracy: 0.5625 >>> Epoch 240/240 >>> 1/1 [==============================] - 1s 708ms/step - loss: 0.0456 - accuracy: 1.0000 - >>> val_loss: 2.3423 - val_accuracy: 0.5312 Visualizaci\u00f3n del sobreajuste de un lote ```python acc = history_overfiting.history['accuracy'] loss = history_overfiting.history['loss'] epochs = range(1, len(acc)+1, 1) fig, axs = plt.subplots(2, 1,figsize=(8, 6)) axs[0].plot(epochs, acc, 'r--', label='Training acc') axs[0].set_title('Training accuracy') axs[0].set_ylabel('acc') axs[0].set_xlabel('epochs') axs[0].legend() axs[1].plot(epochs, loss, 'r--' ) axs[1].set_title ('Training loss') axs[1].set_ylabel('loss') axs[1].set_xlabel('epochs') axs[0].legend() fig.tight_layout() plt.show() ``` Disminuci\u00f3n de la p\u00e9rdida en el entrenamiento: Hasta ahora se estaba trabajando con un modelo simple y liviano, con pocos par\u00e1metros y que permite verificar el correcto funcionamiento de la red. Por ello, ahora se procede a aumentar la capacidad del modelo solo un poco, y seguidamente verificar si realmente la p\u00e9rdida en el entrenamiento ha bajado como se esperaba. Modelo y funci\u00f3n de entrenamiento ```python def make_model_inc_params(input_shape, num_classes): inputs = keras.Input(shape=input_shape) x = layers.experimental.preprocessing.Rescaling(1.0 / 255)(inputs) x = layers.Conv2D(128, 3, strides=3, padding=\"same\")(x) x = layers.Activation(\"relu\")(x) x = layers.MaxPool2D(pool_size=2)(x) x = layers.Conv2D(128, 3, strides=3, padding=\"same\")(x) x = layers.Activation(\"relu\")(x) x = layers.GlobalAveragePooling2D()(x) if num_classes == 2: activation = \"sigmoid\" units = 1 else: activation = \"softmax\" units = num_classes initializer_weights = tf.keras.initializers.GlorotUniform() initializer_bias = tf.constant_initializer(0.6) outputs = layers.Dense(units, bias_initializer = initializer_bias, kernel_initializer = initializer_weights, activation = activation)(x) return keras.Model(inputs, outputs) model_inc_params = make_model_inc_params(input_shape=image_size + (3,), num_classes=num_classes) model_inc_params.compile( optimizer=keras.optimizers.Adam(1e-3), loss=\"binary_crossentropy\", metrics=[\"accuracy\"], ) history_inc_params = model_inc_params.fit( train_ds, epochs=EPOCHS, validation_data=val_ds, validation_steps = len(val_ds) ) ``` >>> Epoch 1/5 >>> 471/471 [==============================] - 52s 109ms/step - loss: 0.6631 - accuracy: 0.6173 - >>> val_loss: 0.6573 - val_accuracy: 0.6259 >>> Epoch 2/5 >>> 471/471 [==============================] - 50s 107ms/step - loss: 0.6448 - accuracy: 0.6249 - >>> val_loss: 0.6292 - val_accuracy: 0.6322 >>> ... >>> ... >>> Epoch 98/100 >>> 472/472 [==============================] - 47s 99ms/step - loss: 0.3319 - accuracy: 0.8548 - >>> val_loss: 0.5061 - val_accuracy: 0.7670 >>> Epoch 99/100 >>> 472/472 [==============================] - 47s 99ms/step - loss: 0.3201 - accuracy: 0.8613 - >>> val_loss: 0.5571 - val_accuracy: 0.7542 >>> Epoch 100/100 >>> 472/472 [==============================] - 47s 100ms/step - loss: 0.3297 - accuracy: 0.8578 - >>> val_loss: 0.5596 - val_accuracy: 0.7545 Visualizaci\u00f3n y comparaci\u00f3n tras el incremento de par\u00e1metros ```python acc = history.history['accuracy'] val_acc = history.history['val_accuracy'] loss = history.history['loss'] val_loss = history.history['val_loss'] acc_aument_params = history_inc_params.history['accuracy'] val_acc_aument_params = history_inc_params.history['val_accuracy'] loss_aument_params = history_inc_params.history['loss'] val_loss_aument_params = history_inc_params.history['val_loss'] epochs = range(1, len(acc)+1, 1) fig, axs = plt.subplots(1, 2, figsize=(12, 5)) axs[0].plot(epochs, acc, 'r--', label='Training acc') axs[0].plot(epochs, val_acc, 'r', label='Validation acc') axs[0].plot(epochs, acc_aument_params, 'b--', label='Training acc +params') axs[0].plot(epochs, val_acc_aument_params, 'b', label='Validation acc +params') axs[0].set_title('Training and validation accuracy') axs[0].set_ylabel('acc') axs[0].set_xlabel('epochs') axs[0].legend() axs[1].plot(epochs, loss, 'r--' ) axs[1].plot(epochs, val_loss , 'r' ) axs[1].plot(epochs, loss_aument_params, 'b--' ) axs[1].plot(epochs, val_loss_aument_params , 'b' ) axs[1].set_title ('Training and validation loss') axs[1].set_ylabel('loss') axs[1].set_xlabel('epochs') fig.tight_layout() plt.show() ``` Generalizaci\u00f3n o estandarizaci\u00f3n del c\u00f3digo: Antes de generalizar una funcionalidad relativamente general desde cero que permita adaptarse a varios casos, se deber\u00eda desarrollar una funci\u00f3n muy espec\u00edfica para cada caso y asegurar que funcione correctamente, para posteriormente codificar la generalizaci\u00f3n de esta. Sobreajuste Antes de empezar con esta etapa, se deber\u00eda tener una buena comprensi\u00f3n del conjunto de datos y un proceso de entrenamiento e inferencia funcionando correctamente. Con ello el modelo es f\u00e1cilmente reproducible y ofrece garant\u00edas en cuanto al c\u00e1lculo de las m\u00e9tricas adoptadas. El enfoque para conseguir un buen modelo se basa en dos etapas: Obtener un modelo lo suficientemente grande como para que pueda ser adaptable en base a la p\u00e9rdida en el proceso de entrenamiento. Posteriormente regularizar el modelo para mejorar la p\u00e9rdida de validaci\u00f3n renunciando a una parte de la p\u00e9rdida del proceso de entrenamiento. Algunos procedimientos a tener en cuenta ser\u00edan: Elecci\u00f3n del modelo: Conseguir una buena p\u00e9rdida en el entrenamiento est\u00e1 relacionado con la elecci\u00f3n de una arquitectura adecuada para los datos de origen. Por ello, no se debe sobredimensionar en exceso la red, sobretodo en las primeras etapas del proyecto. Una buena pr\u00e1ctica es informarse sobre trabajos anteriores en papers que guarden similitud con el proyecto, con ello en las primeras etapas del proyecto es muy aconsejable copiar o adaptar de la mejor forma posible la arquitectura para lograr un buen rendimiento. Por ejemplo, si el proyecto se basa en la clasificaci\u00f3n de im\u00e1genes, una buena pr\u00e1ctica ser\u00eda adaptar una arquitectura conocida como el ResNet-50 o Xception reducida en las primeras fases del proyecto. M\u00e1s tarde se permitir\u00e1 indagar con arquitecturas m\u00e1s personalizables, pero s\u00f3lo si se es capaz de superar esta etapa. ```python def make_model_Xception(input_shape, num_classes, augment=True, Dropout=True, sizes = [128, 256, 512, 728]): inputs = keras.Input(shape=input_shape) # Image augmentation block if augment: x = data_augmentation(inputs) else: x = inputs # Entry block x = layers.experimental.preprocessing.Rescaling(1.0 / 255)(x) x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(x) x = layers.BatchNormalization()(x) x = layers.Activation(\"relu\")(x) x = layers.Conv2D(64, 3, padding=\"same\")(x) x = layers.BatchNormalization()(x) x = layers.Activation(\"relu\")(x) previous_block_activation = x # Set aside residual for size in sizes: x = layers.Activation(\"relu\")(x) x = layers.SeparableConv2D(size, 3, padding=\"same\")(x) x = layers.BatchNormalization()(x) x = layers.Activation(\"relu\")(x) x = layers.SeparableConv2D(size, 3, padding=\"same\")(x) x = layers.BatchNormalization()(x) x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x) # Project residual residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")( previous_block_activation ) x = layers.add([x, residual]) # Add back residual previous_block_activation = x # Set aside next residual x = layers.SeparableConv2D(1024, 3, padding=\"same\")(x) x = layers.BatchNormalization()(x) x = layers.Activation(\"relu\")(x) x = layers.GlobalAveragePooling2D()(x) if num_classes == 2: activation = \"sigmoid\" units = 1 else: activation = \"softmax\" units = num_classes if Dropout: x = layers.Dropout(0.5)(x) outputs = layers.Dense(units, activation=activation)(x) initializer_weights = tf.keras.initializers.GlorotUniform() initializer_bias = tf.constant_initializer(0.6) outputs = layers.Dense(units, bias_initializer = initializer_bias, kernel_initializer = initializer_weights, activation = activation)(x) return keras.Model(inputs, outputs) model_Xception = make_model_Xception(input_shape=image_size + (3,), num_classes=2, augment=False, Dropout=False) ``` Elecci\u00f3n del Optimizador: En las primeras etapas del proyecto, es muy aconsejable utilizar un optimizador conocido y eficiente como es el \"Adam\" con una tasa de aprendizaje de 3e-4. La experiencia nos dice que Adam es mucho m\u00e1s indulgente con los hiperparametros, a\u00fan habiendo establecido una mala tasa de aprendizaje. python optimizer = keras.optimizers.Adam(3e-4) Adicci\u00f3n de complejidad: Para cada cambio en el modelo que induzca a a\u00f1adir mayor complejidad, es recomendable a\u00f1adirlas de una en una, realizando las pruebas pertinentes y asegur\u00e1ndose de que se ha podido conseguir un aumento en el rendimiento sujeto a las expectativas. Disminuci\u00f3n de la tasa de aprendizaje: En las primeras etapas del proyecto se recomienda deshabilitar la disminuci\u00f3n de la tasa de aprendizaje por completo, es decir, establecer una tasa de aprendizaje constante para todo el bucle de entrenamiento. Esto es debido a que los par\u00e1metros por defectos de estas funciones est\u00e1n optimizado para un tipo de redes concretes, que lo m\u00e1s seguro es que no se adapten favorablemente al modelo del proyecto, haciendo que la tasa de aprendizaje decaiga demasiado r\u00e1pido, dificultando que el modelo converja. Posteriormente en las fases finales del proyecto ya se sintonizara estos par\u00e1metros de reducci\u00f3n de la tasa de aprendizaje para conseguir alcanzar el m\u00ednimo valor de p\u00e9rdida de entrenamiento. ```python callbacks = [ # keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, # patience=5, min_lr=0.001) ] model_Xception.compile( optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"], ) history_Xception = model_Xception.fit( train_ds, epochs=EPOCHS, callbacks=callbacks, validation_data=val_ds, validation_steps = len(val_ds) ) ``` >>> Epoch 1/5 >>> 471/471 [==============================] - 338s 717ms/step - loss: 0.5725 - accuracy: 0.6951 - >>> val_loss: 0.6565 - val_accuracy: 0.6190 >>> Epoch 2/5 >>> 471/471 [==============================] - 330s 701ms/step - loss: 0.3821 - accuracy: 0.8303 - >>> val_loss: 0.4466 - val_accuracy: 0.7804 >>> Epoch 3/5 >>> 471/471 [==============================] - 330s 701ms/step - loss: 0.2708 - accuracy: 0.8896 - >>> val_loss: 0.2541 - val_accuracy: 0.8930 >>> Epoch 4/5 >>> 471/471 [==============================] - 331s 702ms/step - loss: 0.1772 - accuracy: 0.9306 - >>> val_loss: 0.2540 - val_accuracy: 0.8911 >>> Epoch 5/5 >>> 471/471 [==============================] - 331s 702ms/step - loss: 0.1140 - accuracy: 0.9590 - >>> val_loss: 0.5719 - val_accuracy: 0.7791 Visualizaci\u00f3n din\u00e1mica de las p\u00e9rdidas y m\u00e9tricas python plot_history(history_Xception) Regularizaci\u00f3n. En esta fase, se tiene un modelo adaptado al conjunto de datos de entrenamiento. Con ello, es el momento de regularizar y obtener cierta precisi\u00f3n del conjunto de validaci\u00f3n renunciando a parte de la precisi\u00f3n en el entrenamiento. Para ello el procedimiento a seguir se basa en: Obtenci\u00f3n de m\u00e1s datos: La mejor forma de regularizar el modelo en cualquier entorno pr\u00e1ctico es agregar m\u00e1s datos de entrenamiento reales. El error m\u00e1s habitual es consumir un gran n\u00famero de recursos y tiempo en tratar de exprimir el jugo a un peque\u00f1o conjunto de datos cuando en su lugar podr\u00eda dedicar estos mismos recursos a la recolecci\u00f3n de nuevos datos. Por ello, podemos concluir que la agregaci\u00f3n de nuevos datos es la forma m\u00e1s eficiente de mejorar el rendimiento de una red neuronal bien configurada. Aumento de los datos: Aplicar t\u00e9cnicas de aumento de datos, basadas en aumentar el conjunto de datos con datos medio falsos. Por ejemplo, en im\u00e1genes se utilizan las rotaciones, las variaciones de color, los cortes parciales de im\u00e1genes, adici\u00f3n de ruido, entre muchas otras t\u00e9cnicas. python data_augmentation = tf.keras.Sequential( [ layers.experimental.preprocessing.RandomFlip(\"horizontal\"), layers.experimental.preprocessing.RandomRotation(0.1), layers.experimental.preprocessing.RandomZoom(height_factor=0.1), layers.experimental.preprocessing.RandomCrop(height=image_size[0]-20, width=image_size[1]-20) ] ) Transformaciones de los datos python inputs = keras.Input(shape=input_shape) x = data_augmentation(inputs) x = layers.experimental.preprocessing.Rescaling(1./255)(x) ... # Rest of the model Con esta opci\u00f3n, el aumento de datos se realizar\u00e1 sincr\u00f3nicamente con el resto de la ejecuci\u00f3n del modelo, lo que significa que se beneficiar\u00e1 de la aceleraci\u00f3n de la GPU. Visualizaci\u00f3n del dataset aplicando el aumento de datos python plt.figure(figsize=(10, 6)) for images, labels in train_ds.take(1): for i in range(8): ax = plt.subplot(2, 4, i + 1) augmented_images = data_augmentation(images) plt.imshow(augmented_images[i].numpy().astype(\"uint8\")) plt.title(\"Cat\" if int(labels[i]) == 0 else \"Dog\") plt.axis(\"off\") Funci\u00f3n de entrenamiento y validaci\u00f3n del modelo con aumento de datos python model_Xception_augment = make_model_Xception(input_shape=image_size + (3,), num_classes=2, augment=True, Dropout=False) model_Xception_augment.compile( optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"], ) history_Xception_augment = model_Xception_augment.fit( train_ds, epochs=EPOCHS, callbacks=callbacks, validation_data=val_ds, validation_steps = len(val_ds) ) >>> Epoch 1/5 >>> 471/471 [==============================] - 306s 650ms/step - loss: 0.6630 - accuracy: 0.6333 - >>> val_loss: 0.9102 - val_accuracy: 0.3810 >>> Epoch 2/5 >>> 471/471 [==============================] - 299s 634ms/step - loss: 0.5456 - accuracy: 0.7252 - >>> val_loss: 0.6306 - val_accuracy: 0.6646 >>> Epoch 3/5 >>> 471/471 [==============================] - 299s 634ms/step - loss: 0.4259 - accuracy: 0.8038 - >>> val_loss: 0.3697 - val_accuracy: 0.8351 >>> Epoch 4/5 >>> 471/471 [==============================] - 298s 633ms/step - loss: 0.3273 - accuracy: 0.8587 - >>> val_loss: 0.2724 - val_accuracy: 0.8826 >>> Epoch 5/5 >>> 471/471 [==============================] - 299s 634ms/step - loss: 0.2736 - accuracy: 0.8820 - >>> val_loss: 0.3086 - val_accuracy: 0.8582 Visualizaci\u00f3n din\u00e1mica de las p\u00e9rdidas y m\u00e9tricas python plot_history(history_Xception_augment) A\u00f1adir p\u00e9rdidas de informaci\u00f3n entre capas: Utilizar capas de abandono (Dropouts) para ConvNets. Siempre utilizando con moderaci\u00f3n ya que un exceso puede generar problemas con la normalizaci\u00f3n por lotes. Funci\u00f3n de entrenamiento y validaci\u00f3n del modelo con capas de abandono en el modelo python model_Xception_dropout_without_augment = make_model_Xception(input_shape=image_size + (3,), num_classes=2, augment=False, Dropout=True) model_Xception_dropout_without_augment.compile( optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"], ) history_Xception_dropout_without_augment = model_Xception_augment.fit( train_ds, epochs=EPOCHS, callbacks=callbacks, validation_data=val_ds, validation_steps = len(val_ds) ) >>> Epoch 1/5 >>> 471/471 [==============================] - 296s 627ms/step - loss: 0.2277 - accuracy: 0.9030 - >>> val_loss: 0.6406 - val_accuracy: 0.7156 >>> Epoch 2/5 >>> 471/471 [==============================] - 296s 629ms/step - loss: 0.2078 - accuracy: 0.9151 - >>> val_loss: 0.2071 - val_accuracy: 0.9164 >>> Epoch 3/5 >>> 471/471 [==============================] - 296s 629ms/step - loss: 0.1850 - accuracy: 0.9247 - >>> val_loss: 0.1692 - val_accuracy: 0.9318 >>> Epoch 4/5 >>> 471/471 [==============================] - 296s 627ms/step - loss: 0.1730 - accuracy: 0.9302 - >>> val_loss: 0.1871 - val_accuracy: 0.9241 >>> Epoch 5/5 >>> 471/471 [==============================] - 295s 627ms/step - loss: 0.1615 - accuracy: 0.9334 - >>> val_loss: 0.1497 - val_accuracy: 0.9379 Visualizaci\u00f3n din\u00e1mica de las p\u00e9rdidas y m\u00e9tricas python plot_history(history_Xception_dropout_without_augment) Aumento de datos creativos: Se est\u00e1n abriendo nuevas l\u00edneas de desarrollo en la expansi\u00f3n de los conjuntos de datos, donde se aplican t\u00e9cnicas de aumento de datos donde dicho dato es totalmente falso (no real). Este tipo de datos se obtienen por ejemplo entrenando redes GANs adaptadas al dominio de los datos, mediante usos de simulaciones, aleatorizaci\u00f3n de dominios, etc. Pre-entrenamiento: No dejar la oportunidad de utilizar una red pre-entrenada para intentar encontrar soluci\u00f3n al problema. Funci\u00f3n de entrenamiento y validaci\u00f3n en base a un modelo pre-entrenado ```python pretrained_model = efn.EfficientNetB0(weights='imagenet', input_shape=(*image_size, 3), include_top=False) pretrained_model.trainable = False def make_model_pretrained(input_shape, num_classes, augment=True, Dropout=True): inputs = keras.Input(shape=input_shape) # Image augmentation block if augment: x = data_augmentation(inputs) else: x = inputs # Entry block X = pretrained_model(x), x = layers.GlobalAveragePooling2D()(x) x = keras.layers.Dense(256, activation='relu')(x) x = keras.layers.Dense(64, activation='relu')(x) if num_classes == 2: activation = \"sigmoid\" units = 1 else: activation = \"softmax\" units = num_classes if Dropout: x = layers.Dropout(0.5)(x) initializer_weights = tf.keras.initializers.GlorotUniform() initializer_bias = tf.constant_initializer(0.6) outputs = layers.Dense(units, bias_initializer = initializer_bias, kernel_initializer = initializer_weights, activation = activation)(x) return keras.Model(inputs, outputs) model_pretrained = make_model_pretrained(input_shape=image_size + (3,), num_classes=2, augment=True, Dropout=False) def unfreeze_model(model): # We unfreeze the top 20 layers while leaving BatchNorm layers frozen for layer in model.layers[-20:]: if not isinstance(layer, layers.BatchNormalization): layer.trainable = True model.compile( optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"] ) unfreeze_model(model_pretrained) history_pretrained = model_pretrained.fit( train_ds, epochs=EPOCHS, callbacks=callbacks, validation_data=val_ds, validation_steps = len(val_ds) ) ``` >>> Epoch 1/5 >>> 471/471 [==============================] - 50s 107ms/step - loss: 1.6228 - accuracy: 0.5647 - >>> val_loss: 0.6702 - val_accuracy: 0.5616 >>> Epoch 2/5 >>> 471/471 [==============================] - 49s 105ms/step - loss: 0.6800 - accuracy: 0.5885 - >>> val_loss: 0.8605 - val_accuracy: 0.6190 >>> Epoch 3/5 >>> 471/471 [==============================] - 49s 105ms/step - loss: 0.6907 - accuracy: 0.5736 - >>> val_loss: 0.6569 - val_accuracy: 0.6184 >>> Epoch 4/5 >>> 471/471 [==============================] - 49s 105ms/step - loss: 0.6878 - accuracy: 0.5796 - >>> val_loss: 0.6502 - val_accuracy: 0.6213 >>> Epoch 5/5 >>> 471/471 [==============================] - 49s 105ms/step - loss: 0.6805 - accuracy: 0.5885 - >>> val_loss: 0.6534 - val_accuracy: 0.6200 Visualizaci\u00f3n din\u00e1mica de las p\u00e9rdidas y m\u00e9tricas python plot_history(history_pretrained) Reducci\u00f3n dimensionalidad de los datos de entrada: Se debe intentar reducir el tama\u00f1o de entrada de los datos al modelo, siempre y cuando se tenga completo conocimiento del dominio de datos. Un indicador para realizar esta reducci\u00f3n de dimensionalidad, es si los detalles de bajo nivel no son muy importantes y se puede prescindir de ellos reduciendo la dimensionalidad. Generaci\u00f3n del Dataset con dimensionalidad de entrada reducida ```python IMAGE_SIZE_REDUCE = (120, 120) train_ds_1 = tf.keras.preprocessing.image_dataset_from_directory( directory, validation_split=0.2, subset=\"training\", seed=seed, image_size=IMAGE_SIZE_REDUCE, batch_size=batch_size, ) val_ds_1 = tf.keras.preprocessing.image_dataset_from_directory( directory, validation_split=0.2, subset=\"validation\", seed=seed, image_size=IMAGE_SIZE_REDUCE, batch_size=batch_size, ) train_ds_1 = train_ds_1.prefetch(buffer_size=batch_size) val_ds_1 = val_ds_1.prefetch(buffer_size=batch_size) model_Xception_augment_dropout_image_reduce = make_model_Xception(input_shape=IMAGE_SIZE_REDUCE + (3,), num_classes=2, augment=False, Dropout=True) model_Xception_augment_dropout_image_reduce.compile( optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"], ) history_Xception_augment_dropout_image_reduce = model_Xception_augment_dropout_image_reduce.fit( train_ds_1, epochs=EPOCHS, callbacks=callbacks, validation_data=val_ds_1, validation_steps = len(val_ds_1) ) ``` >>> Epoch 1/5 >>> 471/471 [==============================] - 101s 214ms/step - loss: 0.6293 - accuracy: 0.6651 - >>> val_loss: 0.7964 - val_accuracy: 0.3834 >>> Epoch 2/5 >>> 471/471 [==============================] - 96s 204ms/step - loss: 0.4061 - accuracy: 0.8171 - >>> val_loss: 0.7718 - val_accuracy: 0.5866 >>> Epoch 3/5 >>> 471/471 [==============================] - 96s 203ms/step - loss: 0.2921 - accuracy: 0.8739 - >>> val_loss: 0.9705 - val_accuracy: 0.5659 >>> Epoch 4/5 >>> 471/471 [==============================] - 95s 202ms/step - loss: 0.1989 - accuracy: 0.9181 - >>> val_loss: 0.3594 - val_accuracy: 0.8537 >>> Epoch 5/5 >>> 471/471 [==============================] - 95s 201ms/step - loss: 0.1228 - accuracy: 0.9506 - >>> val_loss: 1.0463 - val_accuracy: 0.6888 Visualizaci\u00f3n din\u00e1mica de las p\u00e9rdidas y m\u00e9tricas python plot_history(history_Xception_augment_dropout_image_reduce) Disminuci\u00f3n del tama\u00f1o de lote: La reducci\u00f3n del tama\u00f1o de lote (Batchsize) corresponde en cierta medida a una regularizaci\u00f3n m\u00e1s fuerte. Generaci\u00f3n del Dataset con tama\u00f1o de lote reducido ```python BATCH_SIZE_REDUCE = 16 train_ds_1 = tf.keras.preprocessing.image_dataset_from_directory( directory, validation_split=0.2, subset=\"training\", seed=seed, image_size=image_size, batch_size=BATCH_SIZE_REDUCE, ) val_ds_1 = tf.keras.preprocessing.image_dataset_from_directory( directory, validation_split=0.2, subset=\"validation\", seed=seed, image_size=image_size, batch_size=BATCH_SIZE_REDUCE, ) train_ds_1 = train_ds_1.prefetch(buffer_size=batch_size) val_ds_1 = val_ds_1.prefetch(buffer_size=batch_size) model_Xception_augment_dropout_image_reduce_batch_size = make_model_Xception(input_shape=image_size + (3,), num_classes=2, augment=False, Dropout=True) model_Xception_augment_dropout_image_reduce_batch_size.compile( optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"], ) history_Xception_dropout_image_reduce_batchsize = model_Xception_augment_dropout_image_reduce_batch_size.fit( train_ds_1, epochs=EPOCHS, callbacks=callbacks, validation_data=val_ds_1, validation_steps = len(val_ds_1) ) ``` >>> Epoch 1/5 >>> 942/942 [==============================] - 350s 371ms/step - loss: 0.6761 - accuracy: 0.6258 - >>> val_loss: 0.5501 - val_accuracy: 0.7215 >>> Epoch 2/5 >>> 942/942 [==============================] - 346s 367ms/step - loss: 0.5009 - accuracy: 0.7564 - >>> val_loss: 0.4033 - val_accuracy: 0.8205 >>> Epoch 3/5 >>> 942/942 [==============================] - 345s 366ms/step - loss: 0.3535 - accuracy: 0.8489 - >>> val_loss: 0.3670 - val_accuracy: 0.8168 >>> Epoch 4/5 >>> 942/942 [==============================] - 345s 367ms/step - loss: 0.2370 - accuracy: 0.9052 - >>> val_loss: 0.2650 - val_accuracy: 0.8898 >>> Epoch 5/5 >>> 942/942 [==============================] - 344s 365ms/step - loss: 0.1765 - accuracy: 0.9326 - >>> val_loss: 0.2058 - val_accuracy: 0.9126 Visualizaci\u00f3n din\u00e1mica de las p\u00e9rdidas y m\u00e9tricas python plot_history(history_Xception_dropout_image_reduce_batchsize) Detecci\u00f3n temprana: Detecci\u00f3n del proceso de entrenamiento en funci\u00f3n de su p\u00e9rdida de validaci\u00f3n para obtener el modelo justo cuando est\u00e9 en el punto de sobreajuste. python callbacks = [ keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.001), keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True), ] Pruebas con modelos m\u00e1s grandes: Puede utilizar modelos con m\u00e1s par\u00e1metros junto con la detecci\u00f3n temprana, ya que muchas veces estos modelos sobredimensionados consiguen mejor rendimiento de \"parada temprana\". Generaci\u00f3n del modelo con una performance mayor ```python model_big = make_model_Xception(input_shape=image_size + (3,), num_classes=2, augment=True, Dropout=True, sizes = [128, 128, 256, 256, 512, 512, 728, 728, 1024]) model_big.compile( optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"], ) history_model_big = model_big.fit( train_ds, epochs=EPOCHS, callbacks=callbacks, validation_data=val_ds, validation_steps = len(val_ds) ) ``` >>> Epoch 1/5 >>> 471/471 [==============================] - 252s 534ms/step - loss: 0.7830 - accuracy: 0.5869 - >>> val_loss: 0.6550 - val_accuracy: 0.6190 >>> Epoch 2/5 >>> 471/471 [==============================] - 243s 516ms/step - loss: 0.6215 - accuracy: 0.6658 - >>> val_loss: 0.5032 - val_accuracy: 0.7499 >>> Epoch 3/5 >>> 471/471 [==============================] - 243s 517ms/step - loss: 0.5238 - accuracy: 0.7387 - >>> val_loss: 0.5738 - val_accuracy: 0.7384 >>> Epoch 4/5 >>> 471/471 [==============================] - 243s 516ms/step - loss: 0.4359 - accuracy: 0.7987 - >>> val_loss: 0.4106 - val_accuracy: 0.8163 >>> Epoch 5/5 >>> 471/471 [==============================] - 244s 517ms/step - loss: 0.3561 - accuracy: 0.8426 - >>> val_loss: 0.4146 - val_accuracy: 0.8083 Visualizaci\u00f3n din\u00e1mica de las p\u00e9rdidas y m\u00e9tricas python plot_history(history_model_big) A continuaci\u00f3n se expone el estudio de ablaci\u00f3n realizado a partir de todas las iteraciones realizadas: resumen = [ history, history_inc_params, history_model_big, history_pretrained, history_Xception, history_Xception_augment_dropout_image_reduce, history_Xception_dropout_image_reduce_batchsize, history_zeros ] nombres = [ \"basic\", \"inc_params\", \"model_big\", \"pretrained\", \"Xception\", \"Xception_augment_dropout_image_reduce\", \"Xception_dropout_image_reduce_batchsize\", \"zeros\" ] Gr\u00e1fico de visualizaci\u00f3n con la comparaci\u00f3n de todas las configuraciones vistas: fig, axs = plt.subplots(4, 1,figsize=(12, 20)) for hist, name in zip(resumen, nombres): acc = hist.history['accuracy'] val_acc = hist.history['val_accuracy'] loss = hist.history['loss'] val_loss = hist.history['val_loss'] epochs = range(1, len(acc)+1, 1) axs[0].plot(epochs, acc, label=f'{name}') axs[0].set_title('Training accuracy') axs[0].set_ylabel('acc') axs[0].set_xlabel('epochs') axs[0].legend(loc = 'lower right') axs[1].plot(epochs, loss) axs[1].set_title ('Training loss') axs[1].set_ylabel('loss') axs[1].set_xlabel('epochs') axs[2].plot(epochs, val_acc, label=f'{name}') axs[2].set_title('Validation accuracy') axs[2].set_ylabel('acc') axs[2].set_xlabel('epochs') axs[2].legend(loc = 'lower right') axs[3].plot(epochs, val_loss) axs[3].set_title ('Validation loss') axs[3].set_ylabel('loss') axs[3].set_xlabel('epochs') fig.tight_layout() plt.show() Finalmente, como extra para conseguir una confianza adicional de que su red es un clasificador razonable, se pueden visualizar los pesos de la primera capa de la red para asegurarse que tenga bordes suaves con sentido. Es decir, si en los filtros de la primera capa aparece ruido, entonces algo podr\u00eda estar apagado o indicar problemas en las activaciones. Sintonizaci\u00f3n. Una vez se tiene una arquitectura del modelo estable y con gran adaptabilidad al conjunto de datos se puede proceder a la sintonizaci\u00f3n o b\u00fasqueda de los hiperpar\u00e1metros m\u00e1s eficientes. Para ello se puede proceder de la siguiente manera: B\u00fasqueda aleatoria sobre cuadr\u00edcula: Para ajustar simult\u00e1neamente m\u00faltiples hiperpar\u00e1metros, es muy recomendable utilizar la b\u00fasqueda aleatoria frente a la b\u00fasqueda de cuadr\u00edcula. Esto se debe a que las redes neuronales muchas veces son m\u00e1s sensibles a algunos par\u00e1metros que a otros. Optimizaci\u00f3n de hiperpar\u00e1metros: Existe un gran y amplio abanico de opciones para la optimizaci\u00f3n de hiperpar\u00e1metros bayesianas, que ofrecen mejoras significativas y que son opciones a tener en cuenta siempre que se desee realizar este proceso de optimizaci\u00f3n de hiperpar\u00e1metros. Mejoras finales Una vez encontradas las mejores arquitecturas e hiperpar\u00e1metros para el modelo, a\u00fan se puede usar algunas t\u00e9cnicas para aumentar el rendimiento del modelo: Ensembling: Se pueden adaptar como un ensembling varias arquitecturas diferentes que hayan completado todas las etapas anteriores, con ello puede garantizar el aumento de precisi\u00f3n de la red. Detecci\u00f3n temprana del entrenamiento : Una detecci\u00f3n pronta del entrenamiento cuando la p\u00e9rdida por validaci\u00f3n parece estar estabilizandose y sin tener la firme seguridad de haber entrado en overfitting, s\u00f3lo puede ocasionar una p\u00e9rdida de rendimiento notable en el modelo. Connclusiones Una vez llegado a este punto, se puede decir que se ha adquirido un conocimiento profundo de la tecnolog\u00eda, el conjunto de datos y el problema. Se ha configurad una infraestructura de entrenamiento y validaci\u00f3n adquiriendo una gran confianza en la precisi\u00f3n del modelo a trav\u00e9s de las mejoras de rendimiento comentadas.","title":"Pipeline para el entrenamiento de Redes Neuronales"},{"location":"01_Blog/01_Pipeline_NN/doc/Pipeline_para_el_entrenamiento_de_Redes_Neuronales/#pipeline-para-el-entrenamiento-de-redes-neuronales","text":"El objetivo de este post es exponer un proceso especifico cuando se requiera aplicar una red neuronal para abordar un nuevo problema. Se basa en construir la red de simple a complejo, y en cada paso del camino hacer hip\u00f3tesis concretas de lo que se espera que ocurra y posteriormente validarlas con un conjunto de experimentaci\u00f3n que nos permita la detecci\u00f3n pronta de posibles problemas en la arquitectura. Con todo ello, lo que se intenta evitar es introducir una complejidad excesiva a nuestro problema que seguramente introducir\u00e1 errores o configuraciones err\u00f3neas muy dif\u00edciles o casi imposibles de detectar, ya que su red mal configurada, la mayor\u00eda de las veces entrenar\u00e1 sin arrojar excepciones, aunque en silencio funcionar\u00e1 un poco peor.","title":"Pipeline para el entrenamiento de Redes Neuronales"},{"location":"01_Blog/01_Pipeline_NN/doc/Pipeline_para_el_entrenamiento_de_Redes_Neuronales/#analisis-y-limpieza-de-los-datos","text":"El primer paso antes de empezar a crear o desarrollar la arquitectura de la red neuronal es comenzar inspeccionando a fondo sus datos. Este paso es muy cr\u00edtico y por ello se debe dedicar una gran parte del tiempo total al escaneando de miles de ejemplos, entendiendo su distribuci\u00f3n y buscando patrones. Algunas consideraciones a tener en cuenta en el an\u00e1lisis exploratorio y limpieza de datos ser\u00edan: Datos duplicados, en el caso de datos estructurados pueden ser lineas del dataframe repetidas o en el caso de im\u00e1genes podr\u00edan ser copias duplicadas con o sin el mismo nombre. Etiquetas corruptas, datos faltantes o datos inconsistentes. Valores at\u00edpicos en cualquiera de las variables independientes. B\u00fasqueda de los desequilibrios de datos y posibles sesgos en las variables independientes. Estudio que toman la variaci\u00f3n de las variables dependientes. Reducci\u00f3n en la resoluci\u00f3n de las im\u00e1genes siempre que la calidad del detalle sea la apropiada. Posible ruido en las etiquetas o incluso en alguna variable dependiente. Transformaciones de los datos para adaptar la varianza de los datos a una distribuci\u00f3n normal. Categorizaci\u00f3n de las variables categ\u00f3ricas.","title":"An\u00e1lisis y limpieza de los\u00a0Datos"},{"location":"01_Blog/01_Pipeline_NN/doc/Pipeline_para_el_entrenamiento_de_Redes_Neuronales/#descarga-del-dataset-de-ejemplo","text":"data_directory = \"dataset/\" folder_data = \"PetImages/\" directory = os.path.join(data_directory, folder_data) if not os.path.isdir(data_directory): os.mkdir(data_directory) !curl -o dataset/kagglecatsanddogs.zip https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip !unzip -q dataset/kagglecatsanddogs.zip -d dataset/ # Forzar desbalanceo del dataset items_cats = [item for item in os.listdir(os.path.join(directory, \"Cat\")) if os.path.isfile(os.path.join(directory, \"Cat\", item))] _ = [os.remove(os.path.join(directory, \"Cat\", item)) for item in rn.choices(items_cats, k=int(len(items_cats)*0.5)) if os.path.isfile(os.path.join(directory, \"Cat\", item))] !ls dataset/PetImages/ >>> Cat Dog","title":"Descarga del dataset de ejemplo:"},{"location":"01_Blog/01_Pipeline_NN/doc/Pipeline_para_el_entrenamiento_de_Redes_Neuronales/#filtrado-de-imagenes-corruptas","text":"num_skipped = 0 for folder_name in (\"Cat\", \"Dog\"): folder_path = os.path.join(directory, folder_name) for fname in os.listdir(folder_path): fpath = os.path.join(folder_path, fname) try: fobj = open(fpath, \"rb\") is_jfif = tf.compat.as_bytes(\"JFIF\") in fobj.peek(10) finally: fobj.close() if not is_jfif: num_skipped += 1 # Delete corrupted image os.remove(fpath) print(\"Deleted %d images\" % num_skipped) >>> Deleted 0 images","title":"Filtrado de imagenes corruptas"},{"location":"01_Blog/01_Pipeline_NN/doc/Pipeline_para_el_entrenamiento_de_Redes_Neuronales/#resumen-de-los-datos-del-dataset","text":"items_cats = [item for item in os.listdir(os.path.join(directory, \"Cat\")) if os.path.isfile(os.path.join(directory, \"Cat\", item))] items_dogs = [item for item in os.listdir(os.path.join(directory, \"Dog\")) if os.path.isfile(os.path.join(directory, \"Dog\", item))] print(f'Numero de imagenes correspondientes a gatos: {len(items_cats)}') print(f'Numero de imagenes correspondientes a perros: {len(items_dogs)}') print(f'Relaci\u00f3n de desbalanceo gatos/perros: {len(items_cats)/len(items_dogs)}') >>> Numero de imagenes correspondientes a gatos: 7163 >>> Numero de imagenes correspondientes a perros: 11670 >>> Relaci\u00f3n de desbalanceo gatos/perros: 0.613796058269066","title":"Resumen de los Datos del dataset"},{"location":"01_Blog/01_Pipeline_NN/doc/Pipeline_para_el_entrenamiento_de_Redes_Neuronales/#generacion-del-dataset","text":"image_size = (204, 204) batch_size = 32 num_classes = 2 train_ds = tf.keras.preprocessing.image_dataset_from_directory( directory, validation_split=0.2, subset=\"training\", seed=seed, image_size=image_size, batch_size=batch_size, ) val_ds = tf.keras.preprocessing.image_dataset_from_directory( directory, validation_split=0.2, subset=\"validation\", seed=seed, image_size=image_size, batch_size=batch_size, ) train_ds = train_ds.prefetch(buffer_size=batch_size) val_ds = val_ds.prefetch(buffer_size=batch_size) >>> Found 18831 files belonging to 2 classes. >>> Using 15065 files for training. >>> Found 18831 files belonging to 2 classes. >>> Using 3766 files for validation.","title":"Generaci\u00f3n del Dataset"},{"location":"01_Blog/01_Pipeline_NN/doc/Pipeline_para_el_entrenamiento_de_Redes_Neuronales/#visualizacion-de-los-datos","text":"plt.figure(figsize=(10, 6)) for images, labels in train_ds.take(1): for i in range(8): ax = plt.subplot(2, 4, i + 1) plt.imshow(images[i].numpy().astype(\"uint8\")) plt.title(\"Cat\" if int(labels[i]) == 0 else \"Dog\") plt.axis(\"off\")","title":"Visualizaci\u00f3n de los datos"},{"location":"01_Blog/01_Pipeline_NN/doc/Pipeline_para_el_entrenamiento_de_Redes_Neuronales/#configuracion-de-la-arquitectura-end-to-end","text":"Una vez entendidos los datos, el siguiente paso es configurar la funci\u00f3n de entrenamiento y evaluaci\u00f3n, que nos permita ejecutarla y ganar confianza en su inferencia a trav\u00e9s de una serie de experimentos. en esta etapa, es muy recomendable elegir un modelo simple, el cual no ha sido modificado de ninguna manera, por ejemplo, un clasificador lineal o un red convolucional simple. Con ello, el objetivo ser\u00e1 entrenarlo, visualizar las p\u00e9rdidas y las m\u00e9tricas para cada epoch, predecir resultados en base a la inferencia del modelo y realizar una serie de experimentos de ablaci\u00f3n con hip\u00f3tesis expl\u00edcitas en cada experimento realizado.","title":"Configuraci\u00f3n de la arquitectura end-to-end."},{"location":"01_Blog/01_Pipeline_NN/doc/Pipeline_para_el_entrenamiento_de_Redes_Neuronales/#generacion-red-convolucional-simple","text":"def make_model(input_shape, num_classes): inputs = keras.Input(shape=input_shape) # Entry block x = layers.experimental.preprocessing.Rescaling(1.0 / 255)(inputs) x = layers.Conv2D(32, 3, strides=3, padding=\"same\")(x) x = layers.Activation(\"relu\")(x) x = layers.MaxPool2D(pool_size=2)(x) x = layers.Conv2D(32, 3, strides=3, padding=\"same\")(x) x = layers.Activation(\"relu\")(x) x = layers.GlobalAveragePooling2D()(x) if num_classes == 2: activation = \"sigmoid\" units = 1 else: activation = \"softmax\" units = num_classes initializer_weights = tf.keras.initializers.GlorotUniform() initializer_bias = tf.constant_initializer(0.6) outputs = layers.Dense(units, bias_initializer = initializer_bias, kernel_initializer = initializer_weights, activation = activation)(x) return keras.Model(inputs, outputs) model = make_model(input_shape=image_size + (3,), num_classes=num_classes) model.summary() >>> Model: \"functional_1\" >>> _________________________________________________________________ >>> Layer (type) Output Shape Param # >>> ================================================================= >>> input_1 (InputLayer) [(None, 224, 224, 3)] 0 >>> _________________________________________________________________ >>> rescaling (Rescaling) (None, 224, 224, 3) 0 >>> _________________________________________________________________ >>> conv2d (Conv2D) (None, 75, 75, 32) 896 >>> _________________________________________________________________ >>> activation (Activation) (None, 75, 75, 32) 0 >>> _________________________________________________________________ >>> max_pooling2d (MaxPooling2D) (None, 37, 37, 32) 0 >>> _________________________________________________________________ >>> conv2d_1 (Conv2D) (None, 13, 13, 32) 9248 >>> _________________________________________________________________ >>> activation_1 (Activation) (None, 13, 13, 32) 0 >>> _________________________________________________________________ >>> global_average_pooling2d (Gl (None, 32) 0 >>> _________________________________________________________________ >>> dense (Dense) (None, 1) 33 >>> ================================================================= >>> Total params: 10,177 >>> Trainable params: 10,177 >>> Non-trainable params: 0 >>> _________________________________________________________________","title":"Generaci\u00f3n red convolucional simple"},{"location":"01_Blog/01_Pipeline_NN/doc/Pipeline_para_el_entrenamiento_de_Redes_Neuronales/#funcion-de-entrenamiento","text":"EPOCHS = 5 #Par\u00e1metro general en el Pipeline de entrenamiento model.compile( optimizer=keras.optimizers.Adam(1e-3), loss=\"binary_crossentropy\", metrics=[\"accuracy\"], ) history = model.fit( train_ds, epochs=EPOCHS, validation_data=val_ds, validation_steps = len(val_ds) ) >>> Epoch 1/5 >>> 471/471 [==============================] - 49s 104ms/step - loss: 0.6647 - accuracy: 0.6117 - >>> val_loss: 0.6313 - val_accuracy: 0.6283 >>> Epoch 2/5 >>> 471/471 [==============================] - 48s 101ms/step - loss: 0.6322 - accuracy: 0.6346 - >>> val_loss: 0.6266 - val_accuracy: 0.6306 >>> ... >>> ... >>> Epoch 98/100 >>> 472/472 [==============================] - 43s 92ms/step - loss: 0.4487 - accuracy: 0.7835 - >>> val_loss: 0.4857 - val_accuracy: 0.7596 >>> Epoch 99/100 >>> 472/472 [==============================] - 43s 91ms/step - loss: 0.4510 - accuracy: 0.7892 - >>> val_loss: 0.4920 - val_accuracy: 0.7537 >>> Epoch 100/100 >>> 472/472 [==============================] - 43s 91ms/step - loss: 0.4509 - accuracy: 0.7881 - >>> val_loss: 0.5077 - val_accuracy: 0.7503","title":"Funci\u00f3n de entrenamiento"},{"location":"01_Blog/01_Pipeline_NN/doc/Pipeline_para_el_entrenamiento_de_Redes_Neuronales/#funcion-de-evaluacion","text":"def plot_history(history): \"\"\" Generaci\u00f3n del gr\u00e1fico de Visualizaci\u00f3n de m\u00e9tricas y perdidas para cada epochs del entrenamiento-validaci\u00f3n. \"\"\" acc = history.history['accuracy'] val_acc = history.history['val_accuracy'] loss = history.history['loss'] val_loss = history.history['val_loss'] epochs = range(1, len(acc)+1, 1) fig, axs = plt.subplots(1, 2,figsize=(12, 5)) axs[0].plot(epochs, acc, 'r--', label='Training acc') axs[0].plot(epochs, val_acc, 'b', label='Validation acc') axs[0].set_title('Training and validation accuracy') axs[0].set_ylabel('acc') axs[0].set_xlabel('epochs') axs[0].legend() axs[1].plot(epochs, loss, 'r--' ) axs[1].plot(epochs, val_loss , 'b' ) axs[1].set_title ('Training and validation loss') axs[1].set_ylabel('loss') axs[1].set_xlabel('epochs') fig.tight_layout() plt.show() plot_history(history)","title":"Funci\u00f3n de evaluaci\u00f3n"},{"location":"01_Blog/01_Pipeline_NN/doc/Pipeline_para_el_entrenamiento_de_Redes_Neuronales/#sugerencias-a-tener-en-cuenta","text":"Algunas sugerencias en este paso son: Semilla aleatoria fija: esto garantiza la repetibilidad de sus experimentos, eliminando el factor de variaci\u00f3n y permitiendo que pueda comparar los distintos experimentos. ```python","title":"Sugerencias a tener en cuenta"},{"location":"01_Blog/01_Pipeline_NN/doc/Pipeline_para_el_entrenamiento_de_Redes_Neuronales/#configurar-las-semillas-para-reproducibilidad","text":"os.environ['PYTHONHASHSEED'] = '0' seed = 99 np.random.seed(seed) rn.seed(seed) tf.random.set_seed(seed) ``` Simplificar: En esta etapa es muy importante simplificar el pipeline de entrenamiento, es decir, deshabilitar cualquier m\u00e9todo de regulaci\u00f3n a\u00f1adido como por ejemplo podr\u00eda ser el aumento de datos, que pueda inducir alg\u00fan tipo de error en la red. Visualizaci\u00f3n del tensor de entrada de la red: Muy importante preparar en su c\u00f3digo la visualizaci\u00f3n del tensor de entrada a la red. Con ello se asegura la consistencia de los datos de entrada y ayuda a la detecci\u00f3n temprana de fallos en el aumento de datos o en la codificaci\u00f3n de estos. python train_ds.as_numpy_iterator().next()[0].shape >>> (32, 224, 224, 3) Agregar datos significativos en la evaluaci\u00f3n: Evaluar la p\u00e9rdida de evaluaci\u00f3n en todo el conjunto de test. python history = model.fit( train_ds, epochs=EPOCHS, callbacks=callbacks, validation_data=val_ds, validation_steps = total_imag_val // batch_size # con generador: validation_steps = len(val_ds) ) Visualizaci\u00f3n de la din\u00e1mica de predicci\u00f3n: Se pretende visualizar las predicciones del modelo en un lote de prueba fijo durante la inferencia. Esta din\u00e1mica de c\u00f3mo var\u00edan las predicciones permiten intuir de buena manera el progreso de entrenamiento.Si se observa gran variabilidad y fluctuaciones demasiado agresivas, esto es s\u00edntoma de inestabilidades en el proceso de entrenamiento. Verificar la p\u00e9rdida en la inicializaci\u00f3n: Verificar que su p\u00e9rdida comience en un valor de inicializaci\u00f3n correcto. El objetivo de la inicializaci\u00f3n de peso es evitar que las salidas de activaci\u00f3n de la capa exploten o desaparezcan durante el proceso de forward pass de la red neuronal profunda. Si ocurre cualquiera de los dos, los gradientes de p\u00e9rdida ser\u00e1n demasiado grandes o demasiado peque\u00f1os para fluir hacia atr\u00e1s de manera beneficiosa, y la red tardar\u00e1 m\u00e1s en converger, si es que es capaz de hacerlo. Para conseguir una convengencia sustancialmente m\u00e1s r\u00e1pida y una mayor precisi\u00f3n en los resultados, la mejor forma es inicializar los pesos con un inicializador de pesos GlorotNormal o GlorotUniform . python initializer_weights = tf.keras.initializers.GlorotUniform() outputs = layers.Dense(units, kernel_initializer = initializer_weights, activation = activation)(x) Inicializaci\u00f3n de los pesos: Inicializaci\u00f3n de los pesos de las capas finales de manera correcta. Por ejemplo, si se tiene un conjunto de datos desequilibrado a relaci\u00f3n 1:5, se debe asignar el sesgo en los logits de modo que la red sea capaz de predecir la probabilidad de 0.25 en la inicializaci\u00f3n. Esta inicializaci\u00f3n ayudar\u00e1 a la red a converger de manera m\u00e1s r\u00e1pida y eliminar\u00e1 las primeras iteraciones del entrenamiento, donde la red esta aprendiendo el sesgo del conjunto de datos. python print(f'Relaci\u00f3n en el desbalanceo gatos/perros: {len(items_cats)/len(items_dogs)}') >>> Relaci\u00f3n de desbalanceo gatos/perros: 0.613796058269066 En este caso la relaci\u00f3n de desequilibrio entre las dos categorias es de un 0.6 aproximadamente, por ello: python initializer_weights = tf.keras.initializers.GlorotUniform() initializer_bias = tf.constant_initializer(0.6) outputs = layers.Dense(units, bias_initializer = initializer_bias, kernel_initializer = initializer_weights, activation = activation)(x) Razonamiento humano: Monitorizaci\u00f3n de las m\u00e9tricas que no sean p\u00e9rdidas y que aporten m\u00e1s valor al \"ojo humano\", como por ejemplo la precisi\u00f3n siempre que sea posible. Con ello se puede hacer una trazabilidad de los resultados para cada iteraci\u00f3n que sean interpretables desde el programador. python model.compile( optimizer=keras.optimizers.Adam(1e-3), loss=\"binary_crossentropy\", metrics=[\"accuracy\"], ) Independencia de los datos de entrada: Esto se basa en hacer la prueba de entrenar la red neuronal en base a todas las entradas a cero. En este caso la red deber\u00eda funcionar peor que con los datos reales del conjunto de entrenamiento. Si es as\u00ed, se est\u00e1 validando que la red es capaz de extraer informaci\u00f3n de las entradas. En vez de aplicar todas las entradas a zero, se puede establecer una capa de abandono en la entrada, con una tasa/frecuencia de abandono muy alta, con lo que conseguira que practicamente todos los elementos del tensor de entrada sean igual a zero. ```python def make_model_zeros(input_shape, num_classes): inputs = keras.Input(shape=input_shape) x = tf.keras.layers.Dropout(0.99)(inputs) #Aplica Dropout a la entrada. x = layers.Conv2D(32, 3, strides=3, padding=\"same\")(x) x = layers.Activation(\"relu\")(x) x = layers.MaxPool2D(pool_size=2)(x) x = layers.Conv2D(32, 3, strides=3, padding=\"same\")(x) x = layers.Activation(\"relu\")(x) x = layers.GlobalAveragePooling2D()(x) if num_classes == 2: activation = \"sigmoid\" units = 1 else: activation = \"softmax\" units = num_classes initializer_weights = tf.keras.initializers.GlorotUniform() initializer_bias = tf.constant_initializer(0.6) outputs = layers.Dense(units, bias_initializer = initializer_bias, kernel_initializer = initializer_weights, activation = activation)(x) return keras.Model(inputs, outputs) model_zeros = make_model_zeros(input_shape=image_size + (3,), num_classes=num_classes) model_zeros.compile( optimizer=keras.optimizers.Adam(1e-3), loss=\"binary_crossentropy\", metrics=[\"accuracy\"], ) history_zeros = model_zeros.fit( train_ds, epochs=EPOCHS, validation_data=val_ds, validation_steps = len(val_ds) ) ``` >>> Epoch 1/5 >>> 471/471 [==============================] - 49s 103ms/step - loss: 21.5472 - accuracy: 0.5310 - >>> val_loss: 0.6932 - val_accuracy: 0.6190 >>> Epoch 2/5 >>> 471/471 [==============================] - 47s 101ms/step - loss: 1.6109 - accuracy: 0.5280 - >>> val_loss: 0.6682 - val_accuracy: 0.6190 >>> Epoch 3/5 >>> 471/471 [==============================] - 48s 102ms/step - loss: 0.8016 - accuracy: 0.5523 - >>> val_loss: 0.6656 - val_accuracy: 0.6190 >>> ... >>> ... >>> Epoch 98/100 >>> 472/472 [==============================] - 43s 92ms/step - loss: 0.6625 - accuracy: 0.6141 - >>> val_loss: 0.6700 - val_accuracy: 0.6194 >>> Epoch 99/100 >>> 472/472 [==============================] - 44s 93ms/step - loss: 0.6636 - accuracy: 0.6146 - >>> val_loss: 0.6702 - val_accuracy: 0.6194 >>> Epoch 100/100 >>> 472/472 [==============================] - 43s 92ms/step - loss: 0.6644 - accuracy: 0.6131 - >>> val_loss: 0.6709 - val_accuracy: 0.6194 python plot_history(history_zeros) Como se puede observar, la red con una capa de abandono en la entrada no es capaz de converger y por ello no aprende. Con ello, ya que la red base si que convergue, se valida que la red es capaz de extraer informaci\u00f3n de las entradas y como consecuencia se puede decir que el modelo es dependiente de las entradas, es decir, es capaz de extraer informaci\u00f3n de las imagenes de entrada. Sobreajuste en un lote: Se basa en el sobreajuste de un lote de unos poqu\u00edsimos ejemplos, con el objetivo de alcanzar la p\u00e9rdida m\u00e1s baja posible. Para ello se puede aumentar las capacidades de la red, aumentando el n\u00famero de capas o filtros. El objetivo es asegurar que tanto la etiqueta como la predicci\u00f3n coinciden al alcanzar la p\u00e9rdida m\u00ednima, si no es as\u00ed, es s\u00edntoma de que hay alg\u00fan error en alguna parte.","title":"Configurar las semillas para reproducibilidad"},{"location":"01_Blog/01_Pipeline_NN/doc/Pipeline_para_el_entrenamiento_de_Redes_Neuronales/#toma-de-un-unico-lote-para-el-entrenamiento","text":"```python","title":"Toma de un \u00fanico lote para el entrenamiento"},{"location":"01_Blog/01_Pipeline_NN/doc/Pipeline_para_el_entrenamiento_de_Redes_Neuronales/#se-toma-un-lote-a-partir-del-generador-que-servira-como-lote-a-sobreajustar-en-el-entrenamiento","text":"X_train, y_train = train_ds.as_numpy_iterator().next() X_train.shape, y_train.shape ``` >>> ((32, 224, 224, 3), (32,))","title":"Se toma un lote a partir del generador, que servir\u00e1 como lote a sobreajustar en el entrenamiento:"},{"location":"01_Blog/01_Pipeline_NN/doc/Pipeline_para_el_entrenamiento_de_Redes_Neuronales/#modelo-y-funcion-de-entrenamiento","text":"```python def make_model_overfiting(input_shape, num_classes): inputs = keras.Input(shape=input_shape) x = layers.Conv2D(32, 3, strides=3, padding=\"same\")(inputs) x = layers.Activation(\"relu\")(x) x = layers.MaxPool2D(pool_size=2)(x) x = layers.Conv2D(32, 3, strides=3, padding=\"same\")(x) x = layers.Activation(\"relu\")(x) x = layers.GlobalAveragePooling2D()(x) if num_classes == 2: activation = \"sigmoid\" units = 1 else: activation = \"softmax\" units = num_classes initializer_weights = tf.keras.initializers.GlorotUniform() initializer_bias = tf.constant_initializer(0.6) outputs = layers.Dense(units, bias_initializer = initializer_bias, kernel_initializer = initializer_weights, activation = activation)(x) return keras.Model(inputs, outputs) model_overfiting = make_model_overfiting(input_shape=image_size + (3,), num_classes=num_classes) model_overfiting.compile(pip install matplotlib optimizer=keras.optimizers.Adam(1e-3), loss=\"binary_crossentropy\", metrics=[\"accuracy\"], ) history_overfiting = model_overfiting.fit( X_train, y_train, validation_data=val_ds.take(1), validation_steps = len(val_ds.take(1)), epochs=240) #Se eligue un n\u00famero alto de epochs para poder llegar al sobreajuste. ``` >>> Epoch 1/240 >>> 1/1 [==============================] - 1s 1s/step - loss: 13.0985 - accuracy: 0.5312 - >>> val_loss: 3.7622 - val_accuracy: 0.4062 >>> Epoch 2/240 >>> 1/1 [==============================] - 1s 712ms/step - loss: 2.9530 - accuracy: 0.5625 - >>> val_loss: 8.5338 - val_accuracy: 0.3750 >>> Epoch 3/240 >>> 1/1 [==============================] - 1s 690ms/step - loss: 6.6881 - accuracy: 0.4688 - >>> val_loss: 7.3043 - val_accuracy: 0.5625 >>> ... >>> ... >>> Epoch 239/240 >>> 1/1 [==============================] - 1s 692ms/step - loss: 0.0461 - accuracy: 1.0000 - >>> val_loss: 5.1547 - val_accuracy: 0.5625 >>> Epoch 240/240 >>> 1/1 [==============================] - 1s 708ms/step - loss: 0.0456 - accuracy: 1.0000 - >>> val_loss: 2.3423 - val_accuracy: 0.5312","title":"Modelo y funci\u00f3n de entrenamiento"},{"location":"01_Blog/01_Pipeline_NN/doc/Pipeline_para_el_entrenamiento_de_Redes_Neuronales/#visualizacion-del-sobreajuste-de-un-lote","text":"```python acc = history_overfiting.history['accuracy'] loss = history_overfiting.history['loss'] epochs = range(1, len(acc)+1, 1) fig, axs = plt.subplots(2, 1,figsize=(8, 6)) axs[0].plot(epochs, acc, 'r--', label='Training acc') axs[0].set_title('Training accuracy') axs[0].set_ylabel('acc') axs[0].set_xlabel('epochs') axs[0].legend() axs[1].plot(epochs, loss, 'r--' ) axs[1].set_title ('Training loss') axs[1].set_ylabel('loss') axs[1].set_xlabel('epochs') axs[0].legend() fig.tight_layout() plt.show() ``` Disminuci\u00f3n de la p\u00e9rdida en el entrenamiento: Hasta ahora se estaba trabajando con un modelo simple y liviano, con pocos par\u00e1metros y que permite verificar el correcto funcionamiento de la red. Por ello, ahora se procede a aumentar la capacidad del modelo solo un poco, y seguidamente verificar si realmente la p\u00e9rdida en el entrenamiento ha bajado como se esperaba.","title":"Visualizaci\u00f3n del sobreajuste de un lote"},{"location":"01_Blog/01_Pipeline_NN/doc/Pipeline_para_el_entrenamiento_de_Redes_Neuronales/#modelo-y-funcion-de-entrenamiento_1","text":"```python def make_model_inc_params(input_shape, num_classes): inputs = keras.Input(shape=input_shape) x = layers.experimental.preprocessing.Rescaling(1.0 / 255)(inputs) x = layers.Conv2D(128, 3, strides=3, padding=\"same\")(x) x = layers.Activation(\"relu\")(x) x = layers.MaxPool2D(pool_size=2)(x) x = layers.Conv2D(128, 3, strides=3, padding=\"same\")(x) x = layers.Activation(\"relu\")(x) x = layers.GlobalAveragePooling2D()(x) if num_classes == 2: activation = \"sigmoid\" units = 1 else: activation = \"softmax\" units = num_classes initializer_weights = tf.keras.initializers.GlorotUniform() initializer_bias = tf.constant_initializer(0.6) outputs = layers.Dense(units, bias_initializer = initializer_bias, kernel_initializer = initializer_weights, activation = activation)(x) return keras.Model(inputs, outputs) model_inc_params = make_model_inc_params(input_shape=image_size + (3,), num_classes=num_classes) model_inc_params.compile( optimizer=keras.optimizers.Adam(1e-3), loss=\"binary_crossentropy\", metrics=[\"accuracy\"], ) history_inc_params = model_inc_params.fit( train_ds, epochs=EPOCHS, validation_data=val_ds, validation_steps = len(val_ds) ) ``` >>> Epoch 1/5 >>> 471/471 [==============================] - 52s 109ms/step - loss: 0.6631 - accuracy: 0.6173 - >>> val_loss: 0.6573 - val_accuracy: 0.6259 >>> Epoch 2/5 >>> 471/471 [==============================] - 50s 107ms/step - loss: 0.6448 - accuracy: 0.6249 - >>> val_loss: 0.6292 - val_accuracy: 0.6322 >>> ... >>> ... >>> Epoch 98/100 >>> 472/472 [==============================] - 47s 99ms/step - loss: 0.3319 - accuracy: 0.8548 - >>> val_loss: 0.5061 - val_accuracy: 0.7670 >>> Epoch 99/100 >>> 472/472 [==============================] - 47s 99ms/step - loss: 0.3201 - accuracy: 0.8613 - >>> val_loss: 0.5571 - val_accuracy: 0.7542 >>> Epoch 100/100 >>> 472/472 [==============================] - 47s 100ms/step - loss: 0.3297 - accuracy: 0.8578 - >>> val_loss: 0.5596 - val_accuracy: 0.7545","title":"Modelo y funci\u00f3n de entrenamiento"},{"location":"01_Blog/01_Pipeline_NN/doc/Pipeline_para_el_entrenamiento_de_Redes_Neuronales/#visualizacion-y-comparacion-tras-el-incremento-de-parametros","text":"```python acc = history.history['accuracy'] val_acc = history.history['val_accuracy'] loss = history.history['loss'] val_loss = history.history['val_loss'] acc_aument_params = history_inc_params.history['accuracy'] val_acc_aument_params = history_inc_params.history['val_accuracy'] loss_aument_params = history_inc_params.history['loss'] val_loss_aument_params = history_inc_params.history['val_loss'] epochs = range(1, len(acc)+1, 1) fig, axs = plt.subplots(1, 2, figsize=(12, 5)) axs[0].plot(epochs, acc, 'r--', label='Training acc') axs[0].plot(epochs, val_acc, 'r', label='Validation acc') axs[0].plot(epochs, acc_aument_params, 'b--', label='Training acc +params') axs[0].plot(epochs, val_acc_aument_params, 'b', label='Validation acc +params') axs[0].set_title('Training and validation accuracy') axs[0].set_ylabel('acc') axs[0].set_xlabel('epochs') axs[0].legend() axs[1].plot(epochs, loss, 'r--' ) axs[1].plot(epochs, val_loss , 'r' ) axs[1].plot(epochs, loss_aument_params, 'b--' ) axs[1].plot(epochs, val_loss_aument_params , 'b' ) axs[1].set_title ('Training and validation loss') axs[1].set_ylabel('loss') axs[1].set_xlabel('epochs') fig.tight_layout() plt.show() ``` Generalizaci\u00f3n o estandarizaci\u00f3n del c\u00f3digo: Antes de generalizar una funcionalidad relativamente general desde cero que permita adaptarse a varios casos, se deber\u00eda desarrollar una funci\u00f3n muy espec\u00edfica para cada caso y asegurar que funcione correctamente, para posteriormente codificar la generalizaci\u00f3n de esta.","title":"Visualizaci\u00f3n y comparaci\u00f3n tras el incremento de par\u00e1metros"},{"location":"01_Blog/01_Pipeline_NN/doc/Pipeline_para_el_entrenamiento_de_Redes_Neuronales/#sobreajuste","text":"Antes de empezar con esta etapa, se deber\u00eda tener una buena comprensi\u00f3n del conjunto de datos y un proceso de entrenamiento e inferencia funcionando correctamente. Con ello el modelo es f\u00e1cilmente reproducible y ofrece garant\u00edas en cuanto al c\u00e1lculo de las m\u00e9tricas adoptadas. El enfoque para conseguir un buen modelo se basa en dos etapas: Obtener un modelo lo suficientemente grande como para que pueda ser adaptable en base a la p\u00e9rdida en el proceso de entrenamiento. Posteriormente regularizar el modelo para mejorar la p\u00e9rdida de validaci\u00f3n renunciando a una parte de la p\u00e9rdida del proceso de entrenamiento. Algunos procedimientos a tener en cuenta ser\u00edan: Elecci\u00f3n del modelo: Conseguir una buena p\u00e9rdida en el entrenamiento est\u00e1 relacionado con la elecci\u00f3n de una arquitectura adecuada para los datos de origen. Por ello, no se debe sobredimensionar en exceso la red, sobretodo en las primeras etapas del proyecto. Una buena pr\u00e1ctica es informarse sobre trabajos anteriores en papers que guarden similitud con el proyecto, con ello en las primeras etapas del proyecto es muy aconsejable copiar o adaptar de la mejor forma posible la arquitectura para lograr un buen rendimiento. Por ejemplo, si el proyecto se basa en la clasificaci\u00f3n de im\u00e1genes, una buena pr\u00e1ctica ser\u00eda adaptar una arquitectura conocida como el ResNet-50 o Xception reducida en las primeras fases del proyecto. M\u00e1s tarde se permitir\u00e1 indagar con arquitecturas m\u00e1s personalizables, pero s\u00f3lo si se es capaz de superar esta etapa. ```python def make_model_Xception(input_shape, num_classes, augment=True, Dropout=True, sizes = [128, 256, 512, 728]): inputs = keras.Input(shape=input_shape) # Image augmentation block if augment: x = data_augmentation(inputs) else: x = inputs # Entry block x = layers.experimental.preprocessing.Rescaling(1.0 / 255)(x) x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(x) x = layers.BatchNormalization()(x) x = layers.Activation(\"relu\")(x) x = layers.Conv2D(64, 3, padding=\"same\")(x) x = layers.BatchNormalization()(x) x = layers.Activation(\"relu\")(x) previous_block_activation = x # Set aside residual for size in sizes: x = layers.Activation(\"relu\")(x) x = layers.SeparableConv2D(size, 3, padding=\"same\")(x) x = layers.BatchNormalization()(x) x = layers.Activation(\"relu\")(x) x = layers.SeparableConv2D(size, 3, padding=\"same\")(x) x = layers.BatchNormalization()(x) x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x) # Project residual residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")( previous_block_activation ) x = layers.add([x, residual]) # Add back residual previous_block_activation = x # Set aside next residual x = layers.SeparableConv2D(1024, 3, padding=\"same\")(x) x = layers.BatchNormalization()(x) x = layers.Activation(\"relu\")(x) x = layers.GlobalAveragePooling2D()(x) if num_classes == 2: activation = \"sigmoid\" units = 1 else: activation = \"softmax\" units = num_classes if Dropout: x = layers.Dropout(0.5)(x) outputs = layers.Dense(units, activation=activation)(x) initializer_weights = tf.keras.initializers.GlorotUniform() initializer_bias = tf.constant_initializer(0.6) outputs = layers.Dense(units, bias_initializer = initializer_bias, kernel_initializer = initializer_weights, activation = activation)(x) return keras.Model(inputs, outputs) model_Xception = make_model_Xception(input_shape=image_size + (3,), num_classes=2, augment=False, Dropout=False) ``` Elecci\u00f3n del Optimizador: En las primeras etapas del proyecto, es muy aconsejable utilizar un optimizador conocido y eficiente como es el \"Adam\" con una tasa de aprendizaje de 3e-4. La experiencia nos dice que Adam es mucho m\u00e1s indulgente con los hiperparametros, a\u00fan habiendo establecido una mala tasa de aprendizaje. python optimizer = keras.optimizers.Adam(3e-4) Adicci\u00f3n de complejidad: Para cada cambio en el modelo que induzca a a\u00f1adir mayor complejidad, es recomendable a\u00f1adirlas de una en una, realizando las pruebas pertinentes y asegur\u00e1ndose de que se ha podido conseguir un aumento en el rendimiento sujeto a las expectativas. Disminuci\u00f3n de la tasa de aprendizaje: En las primeras etapas del proyecto se recomienda deshabilitar la disminuci\u00f3n de la tasa de aprendizaje por completo, es decir, establecer una tasa de aprendizaje constante para todo el bucle de entrenamiento. Esto es debido a que los par\u00e1metros por defectos de estas funciones est\u00e1n optimizado para un tipo de redes concretes, que lo m\u00e1s seguro es que no se adapten favorablemente al modelo del proyecto, haciendo que la tasa de aprendizaje decaiga demasiado r\u00e1pido, dificultando que el modelo converja. Posteriormente en las fases finales del proyecto ya se sintonizara estos par\u00e1metros de reducci\u00f3n de la tasa de aprendizaje para conseguir alcanzar el m\u00ednimo valor de p\u00e9rdida de entrenamiento. ```python callbacks = [ # keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, # patience=5, min_lr=0.001) ] model_Xception.compile( optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"], ) history_Xception = model_Xception.fit( train_ds, epochs=EPOCHS, callbacks=callbacks, validation_data=val_ds, validation_steps = len(val_ds) ) ``` >>> Epoch 1/5 >>> 471/471 [==============================] - 338s 717ms/step - loss: 0.5725 - accuracy: 0.6951 - >>> val_loss: 0.6565 - val_accuracy: 0.6190 >>> Epoch 2/5 >>> 471/471 [==============================] - 330s 701ms/step - loss: 0.3821 - accuracy: 0.8303 - >>> val_loss: 0.4466 - val_accuracy: 0.7804 >>> Epoch 3/5 >>> 471/471 [==============================] - 330s 701ms/step - loss: 0.2708 - accuracy: 0.8896 - >>> val_loss: 0.2541 - val_accuracy: 0.8930 >>> Epoch 4/5 >>> 471/471 [==============================] - 331s 702ms/step - loss: 0.1772 - accuracy: 0.9306 - >>> val_loss: 0.2540 - val_accuracy: 0.8911 >>> Epoch 5/5 >>> 471/471 [==============================] - 331s 702ms/step - loss: 0.1140 - accuracy: 0.9590 - >>> val_loss: 0.5719 - val_accuracy: 0.7791","title":"Sobreajuste"},{"location":"01_Blog/01_Pipeline_NN/doc/Pipeline_para_el_entrenamiento_de_Redes_Neuronales/#visualizacion-dinamica-de-las-perdidas-y-metricas","text":"python plot_history(history_Xception)","title":"Visualizaci\u00f3n din\u00e1mica de las p\u00e9rdidas y m\u00e9tricas"},{"location":"01_Blog/01_Pipeline_NN/doc/Pipeline_para_el_entrenamiento_de_Redes_Neuronales/#regularizacion","text":"En esta fase, se tiene un modelo adaptado al conjunto de datos de entrenamiento. Con ello, es el momento de regularizar y obtener cierta precisi\u00f3n del conjunto de validaci\u00f3n renunciando a parte de la precisi\u00f3n en el entrenamiento. Para ello el procedimiento a seguir se basa en: Obtenci\u00f3n de m\u00e1s datos: La mejor forma de regularizar el modelo en cualquier entorno pr\u00e1ctico es agregar m\u00e1s datos de entrenamiento reales. El error m\u00e1s habitual es consumir un gran n\u00famero de recursos y tiempo en tratar de exprimir el jugo a un peque\u00f1o conjunto de datos cuando en su lugar podr\u00eda dedicar estos mismos recursos a la recolecci\u00f3n de nuevos datos. Por ello, podemos concluir que la agregaci\u00f3n de nuevos datos es la forma m\u00e1s eficiente de mejorar el rendimiento de una red neuronal bien configurada. Aumento de los datos: Aplicar t\u00e9cnicas de aumento de datos, basadas en aumentar el conjunto de datos con datos medio falsos. Por ejemplo, en im\u00e1genes se utilizan las rotaciones, las variaciones de color, los cortes parciales de im\u00e1genes, adici\u00f3n de ruido, entre muchas otras t\u00e9cnicas. python data_augmentation = tf.keras.Sequential( [ layers.experimental.preprocessing.RandomFlip(\"horizontal\"), layers.experimental.preprocessing.RandomRotation(0.1), layers.experimental.preprocessing.RandomZoom(height_factor=0.1), layers.experimental.preprocessing.RandomCrop(height=image_size[0]-20, width=image_size[1]-20) ] ) Transformaciones de los datos python inputs = keras.Input(shape=input_shape) x = data_augmentation(inputs) x = layers.experimental.preprocessing.Rescaling(1./255)(x) ... # Rest of the model Con esta opci\u00f3n, el aumento de datos se realizar\u00e1 sincr\u00f3nicamente con el resto de la ejecuci\u00f3n del modelo, lo que significa que se beneficiar\u00e1 de la aceleraci\u00f3n de la GPU.","title":"Regularizaci\u00f3n."},{"location":"01_Blog/01_Pipeline_NN/doc/Pipeline_para_el_entrenamiento_de_Redes_Neuronales/#visualizacion-del-dataset-aplicando-el-aumento-de-datos","text":"python plt.figure(figsize=(10, 6)) for images, labels in train_ds.take(1): for i in range(8): ax = plt.subplot(2, 4, i + 1) augmented_images = data_augmentation(images) plt.imshow(augmented_images[i].numpy().astype(\"uint8\")) plt.title(\"Cat\" if int(labels[i]) == 0 else \"Dog\") plt.axis(\"off\")","title":"Visualizaci\u00f3n del dataset aplicando el aumento de datos"},{"location":"01_Blog/01_Pipeline_NN/doc/Pipeline_para_el_entrenamiento_de_Redes_Neuronales/#funcion-de-entrenamiento-y-validacion-del-modelo-con-aumento-de-datos","text":"python model_Xception_augment = make_model_Xception(input_shape=image_size + (3,), num_classes=2, augment=True, Dropout=False) model_Xception_augment.compile( optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"], ) history_Xception_augment = model_Xception_augment.fit( train_ds, epochs=EPOCHS, callbacks=callbacks, validation_data=val_ds, validation_steps = len(val_ds) ) >>> Epoch 1/5 >>> 471/471 [==============================] - 306s 650ms/step - loss: 0.6630 - accuracy: 0.6333 - >>> val_loss: 0.9102 - val_accuracy: 0.3810 >>> Epoch 2/5 >>> 471/471 [==============================] - 299s 634ms/step - loss: 0.5456 - accuracy: 0.7252 - >>> val_loss: 0.6306 - val_accuracy: 0.6646 >>> Epoch 3/5 >>> 471/471 [==============================] - 299s 634ms/step - loss: 0.4259 - accuracy: 0.8038 - >>> val_loss: 0.3697 - val_accuracy: 0.8351 >>> Epoch 4/5 >>> 471/471 [==============================] - 298s 633ms/step - loss: 0.3273 - accuracy: 0.8587 - >>> val_loss: 0.2724 - val_accuracy: 0.8826 >>> Epoch 5/5 >>> 471/471 [==============================] - 299s 634ms/step - loss: 0.2736 - accuracy: 0.8820 - >>> val_loss: 0.3086 - val_accuracy: 0.8582","title":"Funci\u00f3n de entrenamiento y validaci\u00f3n del modelo con aumento de datos"},{"location":"01_Blog/01_Pipeline_NN/doc/Pipeline_para_el_entrenamiento_de_Redes_Neuronales/#visualizacion-dinamica-de-las-perdidas-y-metricas_1","text":"python plot_history(history_Xception_augment) A\u00f1adir p\u00e9rdidas de informaci\u00f3n entre capas: Utilizar capas de abandono (Dropouts) para ConvNets. Siempre utilizando con moderaci\u00f3n ya que un exceso puede generar problemas con la normalizaci\u00f3n por lotes.","title":"Visualizaci\u00f3n din\u00e1mica de las p\u00e9rdidas y m\u00e9tricas"},{"location":"01_Blog/01_Pipeline_NN/doc/Pipeline_para_el_entrenamiento_de_Redes_Neuronales/#funcion-de-entrenamiento-y-validacion-del-modelo-con-capas-de-abandono-en-el-modelo","text":"python model_Xception_dropout_without_augment = make_model_Xception(input_shape=image_size + (3,), num_classes=2, augment=False, Dropout=True) model_Xception_dropout_without_augment.compile( optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"], ) history_Xception_dropout_without_augment = model_Xception_augment.fit( train_ds, epochs=EPOCHS, callbacks=callbacks, validation_data=val_ds, validation_steps = len(val_ds) ) >>> Epoch 1/5 >>> 471/471 [==============================] - 296s 627ms/step - loss: 0.2277 - accuracy: 0.9030 - >>> val_loss: 0.6406 - val_accuracy: 0.7156 >>> Epoch 2/5 >>> 471/471 [==============================] - 296s 629ms/step - loss: 0.2078 - accuracy: 0.9151 - >>> val_loss: 0.2071 - val_accuracy: 0.9164 >>> Epoch 3/5 >>> 471/471 [==============================] - 296s 629ms/step - loss: 0.1850 - accuracy: 0.9247 - >>> val_loss: 0.1692 - val_accuracy: 0.9318 >>> Epoch 4/5 >>> 471/471 [==============================] - 296s 627ms/step - loss: 0.1730 - accuracy: 0.9302 - >>> val_loss: 0.1871 - val_accuracy: 0.9241 >>> Epoch 5/5 >>> 471/471 [==============================] - 295s 627ms/step - loss: 0.1615 - accuracy: 0.9334 - >>> val_loss: 0.1497 - val_accuracy: 0.9379","title":"Funci\u00f3n de entrenamiento y validaci\u00f3n del modelo con capas de abandono en el modelo"},{"location":"01_Blog/01_Pipeline_NN/doc/Pipeline_para_el_entrenamiento_de_Redes_Neuronales/#visualizacion-dinamica-de-las-perdidas-y-metricas_2","text":"python plot_history(history_Xception_dropout_without_augment) Aumento de datos creativos: Se est\u00e1n abriendo nuevas l\u00edneas de desarrollo en la expansi\u00f3n de los conjuntos de datos, donde se aplican t\u00e9cnicas de aumento de datos donde dicho dato es totalmente falso (no real). Este tipo de datos se obtienen por ejemplo entrenando redes GANs adaptadas al dominio de los datos, mediante usos de simulaciones, aleatorizaci\u00f3n de dominios, etc. Pre-entrenamiento: No dejar la oportunidad de utilizar una red pre-entrenada para intentar encontrar soluci\u00f3n al problema.","title":"Visualizaci\u00f3n din\u00e1mica de las p\u00e9rdidas y m\u00e9tricas"},{"location":"01_Blog/01_Pipeline_NN/doc/Pipeline_para_el_entrenamiento_de_Redes_Neuronales/#funcion-de-entrenamiento-y-validacion-en-base-a-un-modelo-pre-entrenado","text":"```python pretrained_model = efn.EfficientNetB0(weights='imagenet', input_shape=(*image_size, 3), include_top=False) pretrained_model.trainable = False def make_model_pretrained(input_shape, num_classes, augment=True, Dropout=True): inputs = keras.Input(shape=input_shape) # Image augmentation block if augment: x = data_augmentation(inputs) else: x = inputs # Entry block X = pretrained_model(x), x = layers.GlobalAveragePooling2D()(x) x = keras.layers.Dense(256, activation='relu')(x) x = keras.layers.Dense(64, activation='relu')(x) if num_classes == 2: activation = \"sigmoid\" units = 1 else: activation = \"softmax\" units = num_classes if Dropout: x = layers.Dropout(0.5)(x) initializer_weights = tf.keras.initializers.GlorotUniform() initializer_bias = tf.constant_initializer(0.6) outputs = layers.Dense(units, bias_initializer = initializer_bias, kernel_initializer = initializer_weights, activation = activation)(x) return keras.Model(inputs, outputs) model_pretrained = make_model_pretrained(input_shape=image_size + (3,), num_classes=2, augment=True, Dropout=False) def unfreeze_model(model): # We unfreeze the top 20 layers while leaving BatchNorm layers frozen for layer in model.layers[-20:]: if not isinstance(layer, layers.BatchNormalization): layer.trainable = True model.compile( optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"] ) unfreeze_model(model_pretrained) history_pretrained = model_pretrained.fit( train_ds, epochs=EPOCHS, callbacks=callbacks, validation_data=val_ds, validation_steps = len(val_ds) ) ``` >>> Epoch 1/5 >>> 471/471 [==============================] - 50s 107ms/step - loss: 1.6228 - accuracy: 0.5647 - >>> val_loss: 0.6702 - val_accuracy: 0.5616 >>> Epoch 2/5 >>> 471/471 [==============================] - 49s 105ms/step - loss: 0.6800 - accuracy: 0.5885 - >>> val_loss: 0.8605 - val_accuracy: 0.6190 >>> Epoch 3/5 >>> 471/471 [==============================] - 49s 105ms/step - loss: 0.6907 - accuracy: 0.5736 - >>> val_loss: 0.6569 - val_accuracy: 0.6184 >>> Epoch 4/5 >>> 471/471 [==============================] - 49s 105ms/step - loss: 0.6878 - accuracy: 0.5796 - >>> val_loss: 0.6502 - val_accuracy: 0.6213 >>> Epoch 5/5 >>> 471/471 [==============================] - 49s 105ms/step - loss: 0.6805 - accuracy: 0.5885 - >>> val_loss: 0.6534 - val_accuracy: 0.6200","title":"Funci\u00f3n de entrenamiento y validaci\u00f3n en base a un modelo pre-entrenado"},{"location":"01_Blog/01_Pipeline_NN/doc/Pipeline_para_el_entrenamiento_de_Redes_Neuronales/#visualizacion-dinamica-de-las-perdidas-y-metricas_3","text":"python plot_history(history_pretrained) Reducci\u00f3n dimensionalidad de los datos de entrada: Se debe intentar reducir el tama\u00f1o de entrada de los datos al modelo, siempre y cuando se tenga completo conocimiento del dominio de datos. Un indicador para realizar esta reducci\u00f3n de dimensionalidad, es si los detalles de bajo nivel no son muy importantes y se puede prescindir de ellos reduciendo la dimensionalidad.","title":"Visualizaci\u00f3n din\u00e1mica de las p\u00e9rdidas y m\u00e9tricas"},{"location":"01_Blog/01_Pipeline_NN/doc/Pipeline_para_el_entrenamiento_de_Redes_Neuronales/#generacion-del-dataset-con-dimensionalidad-de-entrada-reducida","text":"```python IMAGE_SIZE_REDUCE = (120, 120) train_ds_1 = tf.keras.preprocessing.image_dataset_from_directory( directory, validation_split=0.2, subset=\"training\", seed=seed, image_size=IMAGE_SIZE_REDUCE, batch_size=batch_size, ) val_ds_1 = tf.keras.preprocessing.image_dataset_from_directory( directory, validation_split=0.2, subset=\"validation\", seed=seed, image_size=IMAGE_SIZE_REDUCE, batch_size=batch_size, ) train_ds_1 = train_ds_1.prefetch(buffer_size=batch_size) val_ds_1 = val_ds_1.prefetch(buffer_size=batch_size) model_Xception_augment_dropout_image_reduce = make_model_Xception(input_shape=IMAGE_SIZE_REDUCE + (3,), num_classes=2, augment=False, Dropout=True) model_Xception_augment_dropout_image_reduce.compile( optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"], ) history_Xception_augment_dropout_image_reduce = model_Xception_augment_dropout_image_reduce.fit( train_ds_1, epochs=EPOCHS, callbacks=callbacks, validation_data=val_ds_1, validation_steps = len(val_ds_1) ) ``` >>> Epoch 1/5 >>> 471/471 [==============================] - 101s 214ms/step - loss: 0.6293 - accuracy: 0.6651 - >>> val_loss: 0.7964 - val_accuracy: 0.3834 >>> Epoch 2/5 >>> 471/471 [==============================] - 96s 204ms/step - loss: 0.4061 - accuracy: 0.8171 - >>> val_loss: 0.7718 - val_accuracy: 0.5866 >>> Epoch 3/5 >>> 471/471 [==============================] - 96s 203ms/step - loss: 0.2921 - accuracy: 0.8739 - >>> val_loss: 0.9705 - val_accuracy: 0.5659 >>> Epoch 4/5 >>> 471/471 [==============================] - 95s 202ms/step - loss: 0.1989 - accuracy: 0.9181 - >>> val_loss: 0.3594 - val_accuracy: 0.8537 >>> Epoch 5/5 >>> 471/471 [==============================] - 95s 201ms/step - loss: 0.1228 - accuracy: 0.9506 - >>> val_loss: 1.0463 - val_accuracy: 0.6888","title":"Generaci\u00f3n del Dataset con dimensionalidad de entrada reducida"},{"location":"01_Blog/01_Pipeline_NN/doc/Pipeline_para_el_entrenamiento_de_Redes_Neuronales/#visualizacion-dinamica-de-las-perdidas-y-metricas_4","text":"python plot_history(history_Xception_augment_dropout_image_reduce) Disminuci\u00f3n del tama\u00f1o de lote: La reducci\u00f3n del tama\u00f1o de lote (Batchsize) corresponde en cierta medida a una regularizaci\u00f3n m\u00e1s fuerte.","title":"Visualizaci\u00f3n din\u00e1mica de las p\u00e9rdidas y m\u00e9tricas"},{"location":"01_Blog/01_Pipeline_NN/doc/Pipeline_para_el_entrenamiento_de_Redes_Neuronales/#generacion-del-dataset-con-tamano-de-lote-reducido","text":"```python BATCH_SIZE_REDUCE = 16 train_ds_1 = tf.keras.preprocessing.image_dataset_from_directory( directory, validation_split=0.2, subset=\"training\", seed=seed, image_size=image_size, batch_size=BATCH_SIZE_REDUCE, ) val_ds_1 = tf.keras.preprocessing.image_dataset_from_directory( directory, validation_split=0.2, subset=\"validation\", seed=seed, image_size=image_size, batch_size=BATCH_SIZE_REDUCE, ) train_ds_1 = train_ds_1.prefetch(buffer_size=batch_size) val_ds_1 = val_ds_1.prefetch(buffer_size=batch_size) model_Xception_augment_dropout_image_reduce_batch_size = make_model_Xception(input_shape=image_size + (3,), num_classes=2, augment=False, Dropout=True) model_Xception_augment_dropout_image_reduce_batch_size.compile( optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"], ) history_Xception_dropout_image_reduce_batchsize = model_Xception_augment_dropout_image_reduce_batch_size.fit( train_ds_1, epochs=EPOCHS, callbacks=callbacks, validation_data=val_ds_1, validation_steps = len(val_ds_1) ) ``` >>> Epoch 1/5 >>> 942/942 [==============================] - 350s 371ms/step - loss: 0.6761 - accuracy: 0.6258 - >>> val_loss: 0.5501 - val_accuracy: 0.7215 >>> Epoch 2/5 >>> 942/942 [==============================] - 346s 367ms/step - loss: 0.5009 - accuracy: 0.7564 - >>> val_loss: 0.4033 - val_accuracy: 0.8205 >>> Epoch 3/5 >>> 942/942 [==============================] - 345s 366ms/step - loss: 0.3535 - accuracy: 0.8489 - >>> val_loss: 0.3670 - val_accuracy: 0.8168 >>> Epoch 4/5 >>> 942/942 [==============================] - 345s 367ms/step - loss: 0.2370 - accuracy: 0.9052 - >>> val_loss: 0.2650 - val_accuracy: 0.8898 >>> Epoch 5/5 >>> 942/942 [==============================] - 344s 365ms/step - loss: 0.1765 - accuracy: 0.9326 - >>> val_loss: 0.2058 - val_accuracy: 0.9126","title":"Generaci\u00f3n del Dataset con tama\u00f1o de lote reducido"},{"location":"01_Blog/01_Pipeline_NN/doc/Pipeline_para_el_entrenamiento_de_Redes_Neuronales/#visualizacion-dinamica-de-las-perdidas-y-metricas_5","text":"python plot_history(history_Xception_dropout_image_reduce_batchsize) Detecci\u00f3n temprana: Detecci\u00f3n del proceso de entrenamiento en funci\u00f3n de su p\u00e9rdida de validaci\u00f3n para obtener el modelo justo cuando est\u00e9 en el punto de sobreajuste. python callbacks = [ keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.001), keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True), ] Pruebas con modelos m\u00e1s grandes: Puede utilizar modelos con m\u00e1s par\u00e1metros junto con la detecci\u00f3n temprana, ya que muchas veces estos modelos sobredimensionados consiguen mejor rendimiento de \"parada temprana\".","title":"Visualizaci\u00f3n din\u00e1mica de las p\u00e9rdidas y m\u00e9tricas"},{"location":"01_Blog/01_Pipeline_NN/doc/Pipeline_para_el_entrenamiento_de_Redes_Neuronales/#generacion-del-modelo-con-una-performance-mayor","text":"```python model_big = make_model_Xception(input_shape=image_size + (3,), num_classes=2, augment=True, Dropout=True, sizes = [128, 128, 256, 256, 512, 512, 728, 728, 1024]) model_big.compile( optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"], ) history_model_big = model_big.fit( train_ds, epochs=EPOCHS, callbacks=callbacks, validation_data=val_ds, validation_steps = len(val_ds) ) ``` >>> Epoch 1/5 >>> 471/471 [==============================] - 252s 534ms/step - loss: 0.7830 - accuracy: 0.5869 - >>> val_loss: 0.6550 - val_accuracy: 0.6190 >>> Epoch 2/5 >>> 471/471 [==============================] - 243s 516ms/step - loss: 0.6215 - accuracy: 0.6658 - >>> val_loss: 0.5032 - val_accuracy: 0.7499 >>> Epoch 3/5 >>> 471/471 [==============================] - 243s 517ms/step - loss: 0.5238 - accuracy: 0.7387 - >>> val_loss: 0.5738 - val_accuracy: 0.7384 >>> Epoch 4/5 >>> 471/471 [==============================] - 243s 516ms/step - loss: 0.4359 - accuracy: 0.7987 - >>> val_loss: 0.4106 - val_accuracy: 0.8163 >>> Epoch 5/5 >>> 471/471 [==============================] - 244s 517ms/step - loss: 0.3561 - accuracy: 0.8426 - >>> val_loss: 0.4146 - val_accuracy: 0.8083","title":"Generaci\u00f3n del modelo con una performance mayor"},{"location":"01_Blog/01_Pipeline_NN/doc/Pipeline_para_el_entrenamiento_de_Redes_Neuronales/#visualizacion-dinamica-de-las-perdidas-y-metricas_6","text":"python plot_history(history_model_big) A continuaci\u00f3n se expone el estudio de ablaci\u00f3n realizado a partir de todas las iteraciones realizadas: resumen = [ history, history_inc_params, history_model_big, history_pretrained, history_Xception, history_Xception_augment_dropout_image_reduce, history_Xception_dropout_image_reduce_batchsize, history_zeros ] nombres = [ \"basic\", \"inc_params\", \"model_big\", \"pretrained\", \"Xception\", \"Xception_augment_dropout_image_reduce\", \"Xception_dropout_image_reduce_batchsize\", \"zeros\" ]","title":"Visualizaci\u00f3n din\u00e1mica de las p\u00e9rdidas y m\u00e9tricas"},{"location":"01_Blog/01_Pipeline_NN/doc/Pipeline_para_el_entrenamiento_de_Redes_Neuronales/#grafico-de-visualizacion-con-la-comparacion-de-todas-las-configuraciones-vistas","text":"fig, axs = plt.subplots(4, 1,figsize=(12, 20)) for hist, name in zip(resumen, nombres): acc = hist.history['accuracy'] val_acc = hist.history['val_accuracy'] loss = hist.history['loss'] val_loss = hist.history['val_loss'] epochs = range(1, len(acc)+1, 1) axs[0].plot(epochs, acc, label=f'{name}') axs[0].set_title('Training accuracy') axs[0].set_ylabel('acc') axs[0].set_xlabel('epochs') axs[0].legend(loc = 'lower right') axs[1].plot(epochs, loss) axs[1].set_title ('Training loss') axs[1].set_ylabel('loss') axs[1].set_xlabel('epochs') axs[2].plot(epochs, val_acc, label=f'{name}') axs[2].set_title('Validation accuracy') axs[2].set_ylabel('acc') axs[2].set_xlabel('epochs') axs[2].legend(loc = 'lower right') axs[3].plot(epochs, val_loss) axs[3].set_title ('Validation loss') axs[3].set_ylabel('loss') axs[3].set_xlabel('epochs') fig.tight_layout() plt.show() Finalmente, como extra para conseguir una confianza adicional de que su red es un clasificador razonable, se pueden visualizar los pesos de la primera capa de la red para asegurarse que tenga bordes suaves con sentido. Es decir, si en los filtros de la primera capa aparece ruido, entonces algo podr\u00eda estar apagado o indicar problemas en las activaciones.","title":"Gr\u00e1fico de visualizaci\u00f3n con la comparaci\u00f3n de todas las configuraciones vistas:"},{"location":"01_Blog/01_Pipeline_NN/doc/Pipeline_para_el_entrenamiento_de_Redes_Neuronales/#sintonizacion","text":"Una vez se tiene una arquitectura del modelo estable y con gran adaptabilidad al conjunto de datos se puede proceder a la sintonizaci\u00f3n o b\u00fasqueda de los hiperpar\u00e1metros m\u00e1s eficientes. Para ello se puede proceder de la siguiente manera: B\u00fasqueda aleatoria sobre cuadr\u00edcula: Para ajustar simult\u00e1neamente m\u00faltiples hiperpar\u00e1metros, es muy recomendable utilizar la b\u00fasqueda aleatoria frente a la b\u00fasqueda de cuadr\u00edcula. Esto se debe a que las redes neuronales muchas veces son m\u00e1s sensibles a algunos par\u00e1metros que a otros. Optimizaci\u00f3n de hiperpar\u00e1metros: Existe un gran y amplio abanico de opciones para la optimizaci\u00f3n de hiperpar\u00e1metros bayesianas, que ofrecen mejoras significativas y que son opciones a tener en cuenta siempre que se desee realizar este proceso de optimizaci\u00f3n de hiperpar\u00e1metros.","title":"Sintonizaci\u00f3n."},{"location":"01_Blog/01_Pipeline_NN/doc/Pipeline_para_el_entrenamiento_de_Redes_Neuronales/#mejoras-finales","text":"Una vez encontradas las mejores arquitecturas e hiperpar\u00e1metros para el modelo, a\u00fan se puede usar algunas t\u00e9cnicas para aumentar el rendimiento del modelo: Ensembling: Se pueden adaptar como un ensembling varias arquitecturas diferentes que hayan completado todas las etapas anteriores, con ello puede garantizar el aumento de precisi\u00f3n de la red. Detecci\u00f3n temprana del entrenamiento : Una detecci\u00f3n pronta del entrenamiento cuando la p\u00e9rdida por validaci\u00f3n parece estar estabilizandose y sin tener la firme seguridad de haber entrado en overfitting, s\u00f3lo puede ocasionar una p\u00e9rdida de rendimiento notable en el modelo.","title":"Mejoras finales"},{"location":"01_Blog/01_Pipeline_NN/doc/Pipeline_para_el_entrenamiento_de_Redes_Neuronales/#connclusiones","text":"Una vez llegado a este punto, se puede decir que se ha adquirido un conocimiento profundo de la tecnolog\u00eda, el conjunto de datos y el problema. Se ha configurad una infraestructura de entrenamiento y validaci\u00f3n adquiriendo una gran confianza en la precisi\u00f3n del modelo a trav\u00e9s de las mejoras de rendimiento comentadas.","title":"Connclusiones"},{"location":"01_Blog/02_AI_Industria/doc/AI_Industria/","text":"Inteligencia Artificial Aplicada a la Industria sector industrial en estos tiempos afronta un enorme desaf\u00edo para ganar competitividad en plena transformaci\u00f3n digital, en un mercado donde los nuevos h\u00e1bitos de consumo nos obligan a reinventar una nueva forma de fabricar y visibilizar nuestros productos. Estamos abocados a una nueva relaci\u00f3n con los clientes donde se prime la personalizaci\u00f3n y la poca estandarizaci\u00f3n del producto, dirigido a clientes cada vez m\u00e1s interesados en acortar los plazos oblig\u00e1ndonos a ser m\u00e1s \u00e1giles y m\u00e1s r\u00e1pidos. Conseguir todo esto sin aumentar los costes, manteniendo la calidad y mejorando el servicio, s\u00f3lo ser\u00e1 posible implementando el Aprendizaje autom\u00e1tico de las m\u00e1quinas, o bien en lenguaje anglosaj\u00f3n el Machine learning . Todo esto bajo el contexto de la Industria 4.0 , abriendo un gran abanico de oportunidades en la cadena de producci\u00f3n, incrementando la productividad, reduciendo costes, ganando eficiencia a partir del an\u00e1lisis de los datos y optimizando la cadena de producci\u00f3n en tiempo real con la ayuda de algoritmos espec\u00edficos para ello. A continuaci\u00f3n, veamos con detenimiento las ventajas que ofrece el Machine Learning aplicado a la fabricaci\u00f3n avanzada: An\u00e1lisis de los datos. Partimos de que la digitalizaci\u00f3n debe ser general en todos los \u00e1mbitos, es decir, debe extenderse a todos los departamentos y convertirse en una estrategia b\u00e1sica para el cometido que estamos buscando. Esto pasa por hacer un esfuerzo previo importante para la extracci\u00f3n de la informaci\u00f3n, como por ejemplo sensorizar e ingerir todo el enorme volumen de datos que producimos. Solo con esto, seremos capaces de integrarlos en todas las \u00e1reas ofreciendo una visualizaci\u00f3n de conjunto, pudiendo de esta manera destacar las relaciones y tendencias que nos permitan tomar mejores decisiones. Con ello, el proceso productivo en s\u00ed es capaz de aprender y ofrecer una toma de decisiones en tiempo real bajo contextos o escenarios diferentes de producci\u00f3n. Algunos ejemplos sobre este nuevo paradigma podr\u00edan ser: Conociendo el estado de las m\u00e1quinas, el sistema podr\u00eda ser capaz de redistribuir la fabricaci\u00f3n para evitar p\u00e9rdidas y aumentar el rendimiento en la cadena de producci\u00f3n. Comprobar el stock y/o capacidad de almac\u00e9n para evitar carencia en el suministro y satisfacer las necesidades de producto en de los pedidos. Con el estudio de las series temporales en la sensorizaci\u00f3n de las m\u00e1quinas y mergeando los eventos de fallos y/o comportamientos an\u00f3malos, podr\u00edamos anticiparnos a situaciones que puedan comprometer al proceso productivo. An\u00e1lisis Predictivo. Una buena recopilaci\u00f3n de los datos como secuencias de tiempo y etiquetado correcto de los eventos generados en la cadena de producci\u00f3n permite al sistema anticiparse a eventos o estados y circunstancias nuevas para el sistema. A nivel de producci\u00f3n, permite anticiparse a predecir nuevos pedidos de clientes habituales o identificar nuevos patrones de consumo en un nicho de mercado. Esto nos proporciona una fuerte capacidad de adaptaci\u00f3n a la carga de trabajo de las m\u00e1quinas pudiendo hacer frente al incremento del volumen de pedidos consiguiendo un notable incremento en las ventas. A otros niveles, como el de inventario, nos ayuda a gestionar de manera m\u00e1s \u00f3ptima el stock, con el objetivo principal de prevenir un posible desabastecimiento. Esta capacidad de predicci\u00f3n y anticipaci\u00f3n a nuevos eventos es extrapolable a otros procesos como los de mantenimiento, de manera que el sistema es capaz de detectar aver\u00edas antes de que estas ocurran, evitando paros productivos y posibles fallos en la calidad del producto. Automatizaci\u00f3n Inteligente. Como se ha destacado anteriormente, este nuevo paradigma posibilita al sistema productivo a ser capaz de predecir y anticiparse, pero tambi\u00e9n a partir de todo el an\u00e1lisis de datos, el sistema confecciona nuevas estrategias para cumplir su cometido y obtener la mayor recompensa. Es decir, el sistema aprende y posibilita la mejora continua del proceso a partir de relaciones ocultas entre los datos, con el objetivo de maximizar sus recompensas a medida que la pol\u00edtica de toma de decisiones o acciones se optimiza cada vez m\u00e1s en base a la experiencia . Con el t\u00e9rmino experiencia se est\u00e1 refiriendo al feedback de los estados y objetos monitorizados, por ello se dice que el sistema aprende. Con ello, las m\u00e1quinas van aprendiendo a partir de las incidencias y estados concretos del mundo real, como podr\u00eda ser: paradas imprevistas, pedidos urgentes, falta de personal, cuellos de botella, beneficios varios, etc. A partir de este feedback de los estados reales del sistema, el proceso productivo automatiza las acciones m\u00e1s \u00f3ptimas dado el proceso de aprendizaje acometido y que le permite tomar la pol\u00edtica de acciones \u00f3ptima para mantener el proceso productivo en las consignas de valores de rendimiento esperados. Con todo lo comentado se puede llegar a la conclusi\u00f3n de que, con un sistema de estas caracter\u00edsticas y fortalezas, ya no es necesaria la presencia de un operario en la planta, pudiendo \u00e9ste dedicarse a otras actividades de creaci\u00f3n de valor. Con creaci\u00f3n de valor se hace referencia a poder potenciar otras dotes del ser humano, como la de seguir ense\u00f1ando a las m\u00e1quinas a identificar patrones de no-calidad o patrones subjetivos de prevenci\u00f3n, reduciendo as\u00ed las incidencias y los picos de ineficiencia en el trabajo del operario, pudiendo las personas poner el foco en otras \u00e1reas de m\u00e1s valor a\u00f1adido. An\u00e1lisis de disposici\u00f3n. Con esta herramienta se es capaz de visualizar y realizar predicciones en base a la capacidad del sistema para hacer frente a la demanda productiva. En este sentido, si el sistema determina que el proceso productivo no va a ser capaces de asumir una determinada carga de trabajo en los plazos establecidos, eval\u00faa los posibles retrasos en otros pedidos y automatiza posibles alternativas siempre y cuando sea posible. De igual manera, al tener toda la informaci\u00f3n en tiempo real, el sistema puede ser capaz de recomendar precios teniendo en cuenta los gastos productivos y la demanda. De tal manera que el sistema podr\u00eda prescribir tarifas adecu\u00e1ndose a los m\u00e1rgenes. Personalizaci\u00f3n Con este novedoso sistema podemos pasar la personalizaci\u00f3n del producto a primer plano y dejar en segundo plano la fabricaci\u00f3n en masa. Con ello, se priman los pedidos a la carta, de los cuales con la Inteligencia Artificial ya no har\u00e1 falta que una persona est\u00e9 pendiente de la customizaci\u00f3n. Esta personalizaci\u00f3n ser\u00e1 posible hacerse con la m\u00e1xima precisi\u00f3n y producci\u00f3n r\u00e1pida, atendiendo a un nuevo modelo de negocio para la ind\u00fastria donde se personifica el producto en base a diferentes perfiles de demanda, escalando a otro nivel m\u00e1s all\u00e1 de la fabricaci\u00f3n y venta del producto. Esto se resume en la posibilidad de ofrecer servicios basados en el producto, potenciando la personalizaci\u00f3n del mismo. Apostemos, pues, por estas herramientas disruptivas, no s\u00f3lo para no perder competitividad, sino tambi\u00e9n para situarnos como empresas de referencia en la digitalizaci\u00f3n. Si quieres conocer m\u00e1s acerca de mi, visita: https://www.jaimesendraberenguer.com/","title":"Inteligencia Artificial Aplicada a la Industria"},{"location":"01_Blog/02_AI_Industria/doc/AI_Industria/#inteligencia-artificial-aplicada-a-la-industria","text":"sector industrial en estos tiempos afronta un enorme desaf\u00edo para ganar competitividad en plena transformaci\u00f3n digital, en un mercado donde los nuevos h\u00e1bitos de consumo nos obligan a reinventar una nueva forma de fabricar y visibilizar nuestros productos. Estamos abocados a una nueva relaci\u00f3n con los clientes donde se prime la personalizaci\u00f3n y la poca estandarizaci\u00f3n del producto, dirigido a clientes cada vez m\u00e1s interesados en acortar los plazos oblig\u00e1ndonos a ser m\u00e1s \u00e1giles y m\u00e1s r\u00e1pidos. Conseguir todo esto sin aumentar los costes, manteniendo la calidad y mejorando el servicio, s\u00f3lo ser\u00e1 posible implementando el Aprendizaje autom\u00e1tico de las m\u00e1quinas, o bien en lenguaje anglosaj\u00f3n el Machine learning . Todo esto bajo el contexto de la Industria 4.0 , abriendo un gran abanico de oportunidades en la cadena de producci\u00f3n, incrementando la productividad, reduciendo costes, ganando eficiencia a partir del an\u00e1lisis de los datos y optimizando la cadena de producci\u00f3n en tiempo real con la ayuda de algoritmos espec\u00edficos para ello. A continuaci\u00f3n, veamos con detenimiento las ventajas que ofrece el Machine Learning aplicado a la fabricaci\u00f3n avanzada:","title":"Inteligencia Artificial Aplicada a la Industria"},{"location":"01_Blog/02_AI_Industria/doc/AI_Industria/#analisis-de-los-datos","text":"Partimos de que la digitalizaci\u00f3n debe ser general en todos los \u00e1mbitos, es decir, debe extenderse a todos los departamentos y convertirse en una estrategia b\u00e1sica para el cometido que estamos buscando. Esto pasa por hacer un esfuerzo previo importante para la extracci\u00f3n de la informaci\u00f3n, como por ejemplo sensorizar e ingerir todo el enorme volumen de datos que producimos. Solo con esto, seremos capaces de integrarlos en todas las \u00e1reas ofreciendo una visualizaci\u00f3n de conjunto, pudiendo de esta manera destacar las relaciones y tendencias que nos permitan tomar mejores decisiones. Con ello, el proceso productivo en s\u00ed es capaz de aprender y ofrecer una toma de decisiones en tiempo real bajo contextos o escenarios diferentes de producci\u00f3n. Algunos ejemplos sobre este nuevo paradigma podr\u00edan ser: Conociendo el estado de las m\u00e1quinas, el sistema podr\u00eda ser capaz de redistribuir la fabricaci\u00f3n para evitar p\u00e9rdidas y aumentar el rendimiento en la cadena de producci\u00f3n. Comprobar el stock y/o capacidad de almac\u00e9n para evitar carencia en el suministro y satisfacer las necesidades de producto en de los pedidos. Con el estudio de las series temporales en la sensorizaci\u00f3n de las m\u00e1quinas y mergeando los eventos de fallos y/o comportamientos an\u00f3malos, podr\u00edamos anticiparnos a situaciones que puedan comprometer al proceso productivo.","title":"An\u00e1lisis de los datos."},{"location":"01_Blog/02_AI_Industria/doc/AI_Industria/#analisis-predictivo","text":"Una buena recopilaci\u00f3n de los datos como secuencias de tiempo y etiquetado correcto de los eventos generados en la cadena de producci\u00f3n permite al sistema anticiparse a eventos o estados y circunstancias nuevas para el sistema. A nivel de producci\u00f3n, permite anticiparse a predecir nuevos pedidos de clientes habituales o identificar nuevos patrones de consumo en un nicho de mercado. Esto nos proporciona una fuerte capacidad de adaptaci\u00f3n a la carga de trabajo de las m\u00e1quinas pudiendo hacer frente al incremento del volumen de pedidos consiguiendo un notable incremento en las ventas. A otros niveles, como el de inventario, nos ayuda a gestionar de manera m\u00e1s \u00f3ptima el stock, con el objetivo principal de prevenir un posible desabastecimiento. Esta capacidad de predicci\u00f3n y anticipaci\u00f3n a nuevos eventos es extrapolable a otros procesos como los de mantenimiento, de manera que el sistema es capaz de detectar aver\u00edas antes de que estas ocurran, evitando paros productivos y posibles fallos en la calidad del producto.","title":"An\u00e1lisis Predictivo."},{"location":"01_Blog/02_AI_Industria/doc/AI_Industria/#automatizacion-inteligente","text":"Como se ha destacado anteriormente, este nuevo paradigma posibilita al sistema productivo a ser capaz de predecir y anticiparse, pero tambi\u00e9n a partir de todo el an\u00e1lisis de datos, el sistema confecciona nuevas estrategias para cumplir su cometido y obtener la mayor recompensa. Es decir, el sistema aprende y posibilita la mejora continua del proceso a partir de relaciones ocultas entre los datos, con el objetivo de maximizar sus recompensas a medida que la pol\u00edtica de toma de decisiones o acciones se optimiza cada vez m\u00e1s en base a la experiencia . Con el t\u00e9rmino experiencia se est\u00e1 refiriendo al feedback de los estados y objetos monitorizados, por ello se dice que el sistema aprende. Con ello, las m\u00e1quinas van aprendiendo a partir de las incidencias y estados concretos del mundo real, como podr\u00eda ser: paradas imprevistas, pedidos urgentes, falta de personal, cuellos de botella, beneficios varios, etc. A partir de este feedback de los estados reales del sistema, el proceso productivo automatiza las acciones m\u00e1s \u00f3ptimas dado el proceso de aprendizaje acometido y que le permite tomar la pol\u00edtica de acciones \u00f3ptima para mantener el proceso productivo en las consignas de valores de rendimiento esperados. Con todo lo comentado se puede llegar a la conclusi\u00f3n de que, con un sistema de estas caracter\u00edsticas y fortalezas, ya no es necesaria la presencia de un operario en la planta, pudiendo \u00e9ste dedicarse a otras actividades de creaci\u00f3n de valor. Con creaci\u00f3n de valor se hace referencia a poder potenciar otras dotes del ser humano, como la de seguir ense\u00f1ando a las m\u00e1quinas a identificar patrones de no-calidad o patrones subjetivos de prevenci\u00f3n, reduciendo as\u00ed las incidencias y los picos de ineficiencia en el trabajo del operario, pudiendo las personas poner el foco en otras \u00e1reas de m\u00e1s valor a\u00f1adido.","title":"Automatizaci\u00f3n Inteligente."},{"location":"01_Blog/02_AI_Industria/doc/AI_Industria/#analisis-de-disposicion","text":"Con esta herramienta se es capaz de visualizar y realizar predicciones en base a la capacidad del sistema para hacer frente a la demanda productiva. En este sentido, si el sistema determina que el proceso productivo no va a ser capaces de asumir una determinada carga de trabajo en los plazos establecidos, eval\u00faa los posibles retrasos en otros pedidos y automatiza posibles alternativas siempre y cuando sea posible. De igual manera, al tener toda la informaci\u00f3n en tiempo real, el sistema puede ser capaz de recomendar precios teniendo en cuenta los gastos productivos y la demanda. De tal manera que el sistema podr\u00eda prescribir tarifas adecu\u00e1ndose a los m\u00e1rgenes.","title":"An\u00e1lisis de disposici\u00f3n."},{"location":"01_Blog/02_AI_Industria/doc/AI_Industria/#personalizacion","text":"Con este novedoso sistema podemos pasar la personalizaci\u00f3n del producto a primer plano y dejar en segundo plano la fabricaci\u00f3n en masa. Con ello, se priman los pedidos a la carta, de los cuales con la Inteligencia Artificial ya no har\u00e1 falta que una persona est\u00e9 pendiente de la customizaci\u00f3n. Esta personalizaci\u00f3n ser\u00e1 posible hacerse con la m\u00e1xima precisi\u00f3n y producci\u00f3n r\u00e1pida, atendiendo a un nuevo modelo de negocio para la ind\u00fastria donde se personifica el producto en base a diferentes perfiles de demanda, escalando a otro nivel m\u00e1s all\u00e1 de la fabricaci\u00f3n y venta del producto. Esto se resume en la posibilidad de ofrecer servicios basados en el producto, potenciando la personalizaci\u00f3n del mismo. Apostemos, pues, por estas herramientas disruptivas, no s\u00f3lo para no perder competitividad, sino tambi\u00e9n para situarnos como empresas de referencia en la digitalizaci\u00f3n. Si quieres conocer m\u00e1s acerca de mi, visita: https://www.jaimesendraberenguer.com/","title":"Personalizaci\u00f3n"},{"location":"02_Portfolio/example/","text":"Portfolio","title":"Example"},{"location":"02_Portfolio/example/#portfolio","text":"","title":"Portfolio"}]}